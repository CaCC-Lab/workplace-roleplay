"""
app.pyã®é«˜åº¦ãªçµ±åˆãƒ†ã‚¹ãƒˆ - ã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Šã®ãŸã‚
TDDåŸå‰‡ã«å¾“ã„ã€å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã€è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’ãƒ†ã‚¹ãƒˆ
"""
import pytest
import json
import time
from unittest.mock import patch, MagicMock, PropertyMock
from flask import session

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®é–¢æ•°ã¨ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
from app import app


# APIã®ãƒ¢ãƒƒã‚¯è¨­å®šã‚’æœ€åˆã«èª­ã¿è¾¼ã¿
@pytest.fixture(autouse=True)
def mock_all_external_apis():
    """ã™ã¹ã¦ã®å¤–éƒ¨APIå‘¼ã³å‡ºã—ã‚’ãƒ¢ãƒƒã‚¯åŒ–ï¼ˆè‡ªå‹•é©ç”¨ï¼‰"""
    with patch('app.create_gemini_llm') as mock_create_llm, \
         patch('google.generativeai.GenerativeModel') as mock_gemini_model, \
         patch('google.generativeai.configure') as mock_configure, \
         patch('langchain_google_genai.ChatGoogleGenerativeAI') as mock_chat_gemini:
        
        # åŸºæœ¬çš„ãªLLMãƒ¢ãƒƒã‚¯ã‚’è¨­å®š
        mock_llm = MagicMock()
        from langchain_core.messages import AIMessage
        mock_llm.invoke.return_value = AIMessage(content="Test response from mocked LLM")
        mock_llm.astream.return_value = iter([
            MagicMock(content="Test "),
            MagicMock(content="streamed "),
            MagicMock(content="response")
        ])
        
        # create_gemini_llmé–¢æ•°ã‚’ãƒ¢ãƒƒã‚¯
        mock_create_llm.return_value = mock_llm
        
        # ChatGoogleGenerativeAIã‚¯ãƒ©ã‚¹ã‚’ãƒ¢ãƒƒã‚¯
        mock_chat_gemini.return_value = mock_llm
        
        # Gemini Modelã®ãƒ¢ãƒƒã‚¯
        mock_model_instance = MagicMock()
        mock_model_instance.generate_content.return_value = MagicMock(
            text="Mocked response from Gemini API"
        )
        mock_gemini_model.return_value = mock_model_instance
        
        yield {
            'mock_create_llm': mock_create_llm,
            'mock_chat_gemini': mock_chat_gemini,
            'mock_gemini_model': mock_gemini_model,
            'mock_configure': mock_configure,
            'mock_llm': mock_llm
        }


class TestComplexWorkflows:
    """è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_multi_turn_conversation_flow(self, csrf_client, mock_all_external_apis):
        """è¤‡æ•°ã‚¿ãƒ¼ãƒ³ã®ä¼šè©±ãƒ•ãƒ­ãƒ¼ã‚’ç¢ºèª"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¨­å®š
        mock_llm = mock_all_external_apis['mock_llm']
        
        # ä¼šè©±ã®å„ã‚¿ãƒ¼ãƒ³ã«ç•°ãªã‚‹å¿œç­”ã‚’è¨­å®š
        responses = [
            "ã“ã‚“ã«ã¡ã¯ï¼ã©ã®ã‚ˆã†ãªãŠè©±ã‚’ã—ã¾ã—ã‚‡ã†ã‹ï¼Ÿ",
            "å¤©æ°—ã®è©±ã§ã™ã­ã€‚ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚",
            "ãã†ã§ã™ã­ã€‚é€±æœ«ã®äºˆå®šã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            "ç´ æ™´ã‚‰ã—ã„ã§ã™ã­ï¼æ¥½ã—ã„æ™‚é–“ã‚’ãŠéã”ã—ãã ã•ã„ã€‚"
        ]
        
        from langchain_core.messages import AIMessage
        mock_responses = [AIMessage(content=resp) for resp in responses]
        mock_llm.invoke.side_effect = mock_responses
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
        with csrf_client.session_transaction() as sess:
            sess['chat_settings'] = {
                "system_prompt": "ã‚ãªãŸã¯è·å ´ã§ã®é›‘è«‡ç·´ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                "model": "gemini-1.5-flash"
            }
        
        # è¤‡æ•°ã‚¿ãƒ¼ãƒ³ã®ä¼šè©±
        messages = [
            "ã“ã‚“ã«ã¡ã¯",
            "ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­",
            "é€±æœ«ã¯å®¶æ—ã¨éã”ã™äºˆå®šã§ã™",
            "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™"
        ]
        
        for i, message in enumerate(messages):
            response = csrf_client.post('/api/chat',
                                 json={
                                     "message": message,
                                     "model": "gemini-1.5-flash"
                                 })
            
            assert response.status_code == 200
            data = response.get_json()
            assert "response" in data
            assert responses[i] in data["response"]
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ãŒæ­£ã—ãç©ã¿ä¸ŠãŒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        with csrf_client.session_transaction() as sess:
            assert 'chat_history' in sess
            assert len(sess['chat_history']) == len(messages)
    
    def test_scenario_practice_complete_flow(self, csrf_client, mock_all_external_apis):
        """ã‚·ãƒŠãƒªã‚ªç·´ç¿’ã®å®Œå…¨ãƒ•ãƒ­ãƒ¼ã‚’ç¢ºèª"""
        mock_llm = mock_all_external_apis['mock_llm']
        
        # ã‚·ãƒŠãƒªã‚ªã®å„æ®µéšã§ã®å¿œç­”
        scenario_responses = [
            "ã„ã‚‰ã£ã—ã‚ƒã„ã¾ã›ã€‚æœ¬æ—¥ã¯ãŠå¿™ã—ã„ä¸­ã€ãŠæ™‚é–“ã‚’ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚",
            "æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚è©³ç´°ã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚",
            "ã“ã¡ã‚‰ã§å¯¾å¿œã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ä»–ã«ã”è³ªå•ã¯ã”ã–ã„ã¾ã™ã‹ï¼Ÿ",
            "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚ã¾ãŸä½•ã‹ã”ã–ã„ã¾ã—ãŸã‚‰ãŠå£°ãŒã‘ãã ã•ã„ã€‚"
        ]
        
        from langchain_core.messages import AIMessage
        mock_responses = [AIMessage(content=resp) for resp in scenario_responses]
        mock_llm.invoke.side_effect = mock_responses + [AIMessage(content="""
## ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢
88ç‚¹

## è‰¯ã‹ã£ãŸç‚¹
- ä¸å¯§ãªæ•¬èªã®ä½¿ç”¨
- ç›¸æ‰‹ã®ç«‹å ´ã«é…æ…®ã—ãŸç™ºè¨€
- é©åˆ‡ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã®è³ªå•

## æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ
- ã‚ˆã‚Šå…·ä½“çš„ãªææ¡ˆã‚’å«ã‚ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†
- æ„Ÿè¬ã®æ°—æŒã¡ã‚’ã‚‚ã†å°‘ã—è¡¨ç¾ã§ãã¾ã™

## ç·åˆè©•ä¾¡
è·å ´ã§ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦éå¸¸ã«è‰¯ã„å¯¾å¿œã§ã—ãŸã€‚
        """)]
        
        # ãƒ¢ãƒƒã‚¯ã¯æ—¢ã«ã‚°ãƒ­ãƒ¼ãƒãƒ«ã§è¨­å®šæ¸ˆã¿
        
        scenario_id = "customer_service"
        user_messages = [
            "ãŠå®¢æ§˜ã€ã„ã‚‰ã£ã—ã‚ƒã„ã¾ã›",
            "ã‹ã—ã“ã¾ã‚Šã¾ã—ãŸã€ç¢ºèªã„ãŸã—ã¾ã™",
            "æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€å¯¾å¿œã„ãŸã—ã¾ã™",
            "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ"
        ]
        
        # ã‚·ãƒŠãƒªã‚ªç·´ç¿’ã®å®Ÿè¡Œ
        for message in user_messages:
            response = csrf_client.post('/api/scenario_chat',
                                 json={
                                     "message": message,
                                     "model": "gemini-1.5-flash",
                                     "scenario_id": scenario_id
                                 })
            
            assert response.status_code == 200
            data = response.get_json()
            assert "response" in data
        
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å–å¾—
        feedback_response = csrf_client.post('/api/scenario_feedback',
                                      json={"scenario_id": scenario_id})
        
        assert feedback_response.status_code == 200
        feedback_data = feedback_response.get_json()
        assert "feedback" in feedback_data
        assert "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢" in feedback_data["feedback"]
        assert "è‰¯ã‹ã£ãŸç‚¹" in feedback_data["feedback"]
        assert "æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ" in feedback_data["feedback"]
    
    # Removed patch decorator - using global mock
    def test_watch_mode_complete_conversation(self, csrf_client, mock_all_external_apis):
        """è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ã®å®Œå…¨ãªä¼šè©±ãƒ•ãƒ­ãƒ¼ã‚’ç¢ºèª"""
        mock_llm = MagicMock()
        
        # è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ã®ä¼šè©±ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
        watch_responses = [
            "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ï¼ä»Šæ—¥ã‚‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€‚",
            "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚æ˜¨æ—¥ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä»¶ã€ã„ã‹ãŒã§ã—ãŸã‹ï¼Ÿ",
            "é †èª¿ã«é€²ã‚“ã§ã„ã¾ã™ã€‚æ¥é€±ã«ã¯å®Œæˆäºˆå®šã§ã™ã€‚",
            "ãã‚Œã¯è‰¯ã‹ã£ãŸã§ã™ã€‚ä½•ã‹ã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ã§ã—ãŸã‚‰ãŠå£°ãŒã‘ãã ã•ã„ã€‚",
            "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚åŠ©ã‹ã‚Šã¾ã™ã€‚"
        ]
        
        from langchain_core.messages import AIMessage
        mock_responses = [AIMessage(content=resp) for resp in watch_responses]
        mock_llm.invoke.side_effect = mock_responses
        
        # è¦³æˆ¦é–‹å§‹
        start_response = csrf_client.post('/api/watch/start',
                                   json={
                                       "model_a": "gemini-1.5-pro",
                                       "model_b": "gemini-1.5-flash",
                                       "partner_type": "colleague",
                                       "situation": "morning",
                                       "topic": "work"
                                   })
        
        assert start_response.status_code == 200
        
        # è¤‡æ•°ã‚¿ãƒ¼ãƒ³ã®ä¼šè©±ã‚’ç”Ÿæˆ
        for i in range(4):
            next_response = csrf_client.post('/api/watch/next')
            
            assert next_response.status_code == 200
            data = next_response.get_json()
            assert "message" in data
            assert "speaker" in data
            assert data["speaker"] in ["A", "B"]
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å®Œå…¨ãªä¼šè©±å±¥æ­´ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        with csrf_client.session_transaction() as sess:
            assert 'watch_history' in sess
            assert len(sess['watch_history']) >= 4


class TestEdgeCases:
    """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_extremely_long_message(self, csrf_client, mock_all_external_apis):
        """æ¥µç«¯ã«é•·ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†ã‚’ç¢ºèª"""
        long_message = "ãƒ†ã‚¹ãƒˆ " * 10000  # éå¸¸ã«é•·ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨
        mock_llm = mock_all_external_apis['mock_llm']
        from langchain_core.messages import AIMessage
        mock_response = AIMessage(content="é•·ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
        mock_llm.invoke.return_value = mock_response
        
        with csrf_client.session_transaction() as sess:
            sess['chat_settings'] = {
                "system_prompt": "ãƒ†ã‚¹ãƒˆ",
                "model": "gemini-1.5-flash"
            }
        
        response = csrf_client.post('/api/chat',
                             json={
                                 "message": long_message,
                                 "model": "gemini-1.5-flash"
                             })
        
        # é•·ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚é©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹
        assert response.status_code in [200, 400]  # åˆ¶é™ã«ã‚ˆã‚Š400ã‚‚å¯èƒ½
    
    def test_special_characters_in_message(self, csrf_client, mock_all_external_apis):
        """ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†ã‚’ç¢ºèª"""
        special_message = "ã“ã‚“ã«ã¡ã¯ï¼@#$%^&*()_+{}|:<>?[]\\;',./`~"
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨
        mock_llm = mock_all_external_apis['mock_llm']
        from langchain_core.messages import AIMessage
        mock_response = AIMessage(content="ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã­")
        mock_llm.invoke.return_value = mock_response
        
        with csrf_client.session_transaction() as sess:
            sess['chat_settings'] = {
                "system_prompt": "ãƒ†ã‚¹ãƒˆ",
                "model": "gemini-1.5-flash"
            }
        
        response = csrf_client.post('/api/chat',
                             json={
                                 "message": special_message,
                                 "model": "gemini-1.5-flash"
                             })
        
        assert response.status_code == 200
        data = response.get_json()
        assert "response" in data
    
    def test_unicode_emoji_handling(self, csrf_client, mock_all_external_apis):
        """Unicodeçµµæ–‡å­—ã®å‡¦ç†ã‚’ç¢ºèª"""
        emoji_message = "ã“ã‚“ã«ã¡ã¯ï¼ğŸ˜ŠğŸŒŸâ­ï¸ğŸ‰ğŸš€ğŸ’–"
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨
        mock_llm = mock_all_external_apis['mock_llm']
        from langchain_core.messages import AIMessage
        mock_response = AIMessage(content="çµµæ–‡å­—ãŒãŸãã•ã‚“ã§ã™ã­ï¼ğŸ˜„")
        mock_llm.invoke.return_value = mock_response
        
        with csrf_client.session_transaction() as sess:
            sess['chat_settings'] = {
                "system_prompt": "ãƒ†ã‚¹ãƒˆ",
                "model": "gemini-1.5-flash"
            }
        
        response = csrf_client.post('/api/chat',
                             json={
                                 "message": emoji_message,
                                 "model": "gemini-1.5-flash"
                             })
        
        assert response.status_code == 200
        data = response.get_json()
        assert "response" in data
        assert "ğŸ˜„" in data["response"]
    
    def test_empty_session_handling(self, csrf_client):
        """ç©ºã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ã®å‡¦ç†ã‚’ç¢ºèª"""
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ„å›³çš„ã«ã‚¯ãƒªã‚¢
        with csrf_client.session_transaction() as sess:
            sess.clear()
        
        response = csrf_client.post('/api/chat',
                             json={
                                 "message": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒãªã„çŠ¶æ…‹ã§ã™",
                                 "model": "gemini-1.5-flash"
                             })
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã§ã‚‚é©åˆ‡ã«åˆæœŸåŒ–ã•ã‚Œã‚‹
        assert response.status_code in [200, 400, 500]
    
    def test_malformed_session_data(self, csrf_client, mock_all_external_apis):
        """ä¸æ­£ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã§ã®å‡¦ç†ã‚’ç¢ºèª"""
        with csrf_client.session_transaction() as sess:
            # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¨­å®š
            sess['chat_history'] = "ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿å½¢å¼"
            sess['chat_settings'] = ["ãƒªã‚¹ãƒˆå½¢å¼", "ä¸æ­£"]
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨
        mock_llm = mock_all_external_apis['mock_llm']
        from langchain_core.messages import AIMessage
        mock_response = AIMessage(content="å¾©æ—§ã—ã¾ã—ãŸ")
        mock_llm.invoke.return_value = mock_response
        
        response = csrf_client.post('/api/chat',
                             json={
                                 "message": "ä¸æ­£ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã®å¾©æ—§",
                                 "model": "gemini-1.5-flash"
                             })
        
        # ä¸æ­£ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚‚é©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹
        assert response.status_code in [200, 500]


class TestConcurrencyAndRace:
    """ä¸¦è¡Œæ€§ã¨ç«¶åˆçŠ¶æ…‹ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_concurrent_session_access(self, csrf_client, mock_all_external_apis):
        """åŒä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã®ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹ã®å‡¦ç†ã‚’ç¢ºèª"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨
        mock_llm = mock_all_external_apis['mock_llm']
        from langchain_core.messages import AIMessage
        mock_response = AIMessage(content="ä¸¦è¡Œå‡¦ç†å¿œç­”")
        mock_llm.invoke.return_value = mock_response
        
        with csrf_client.session_transaction() as sess:
            sess['chat_settings'] = {
                "system_prompt": "ãƒ†ã‚¹ãƒˆ",
                "model": "gemini-1.5-flash"
            }
        
        # è¤‡æ•°ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’çŸ­æ™‚é–“ã§é€ä¿¡
        responses = []
        for i in range(3):
            response = csrf_client.post('/api/chat',
                                 json={
                                     "message": f"ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆ{i}",
                                     "model": "gemini-1.5-flash"
                                 })
            responses.append(response)
        
        # ã™ã¹ã¦ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹
        for response in responses:
            assert response.status_code == 200
    
    def test_session_history_consistency(self, csrf_client, mock_all_external_apis):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã®ä¸€è²«æ€§ã‚’ç¢ºèª"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨
        mock_llm = mock_all_external_apis['mock_llm']
        
        # å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«ç•°ãªã‚‹å¿œç­”ã‚’è¨­å®š
        from langchain_core.messages import AIMessage
        mock_responses = [
            AIMessage(content="å¿œç­”1"),
            AIMessage(content="å¿œç­”2"),
            AIMessage(content="å¿œç­”3")
        ]
        mock_llm.invoke.side_effect = mock_responses
        
        with csrf_client.session_transaction() as sess:
            sess['chat_settings'] = {
                "system_prompt": "ãƒ†ã‚¹ãƒˆ",
                "model": "gemini-1.5-flash"
            }
        
        # é †æ¬¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
        for i in range(3):
            csrf_client.post('/api/chat',
                       json={
                           "message": f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i+1}",
                           "model": "gemini-1.5-flash"
                       })
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã®ä¸€è²«æ€§ã‚’ç¢ºèª
        with csrf_client.session_transaction() as sess:
            history = sess.get('chat_history', [])
            assert len(history) == 3
            for i, entry in enumerate(history):
                assert entry['human'] == f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i+1}"
                assert entry['ai'] == f"å¿œç­”{i+1}"


class TestResourceManagement:
    """ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã®ãƒ†ã‚¹ãƒˆ"""
    
    # Removed patch decorator - using global mock
    def test_memory_efficient_large_history(self, csrf_client, mock_all_external_apis):
        """å¤§ããªå±¥æ­´ã§ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’ç¢ºèª"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨
        mock_llm = mock_all_external_apis['mock_llm']
        from langchain_core.messages import AIMessage
        mock_response = AIMessage(content="ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ†ã‚¹ãƒˆ")
        mock_llm.invoke.return_value = mock_response
        
        # å¤§ããªå±¥æ­´ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¨­å®š
        large_history = []
        for i in range(1000):
            large_history.append({
                "human": f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i}",
                "ai": f"AIå¿œç­”{i}"
            })
        
        with csrf_client.session_transaction() as sess:
            sess['chat_history'] = large_history
            sess['chat_settings'] = {
                "system_prompt": "ãƒ†ã‚¹ãƒˆ",
                "model": "gemini-1.5-flash"
            }
        
        # æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
        response = csrf_client.post('/api/chat',
                             json={
                                 "message": "å¤§ããªå±¥æ­´ã§ã®ãƒ†ã‚¹ãƒˆ",
                                 "model": "gemini-1.5-flash"
                             })
        
        # å¤§ããªå±¥æ­´ãŒã‚ã£ã¦ã‚‚å‡¦ç†ã•ã‚Œã‚‹
        assert response.status_code in [200, 500]
    
    def test_session_cleanup_after_clear(self, csrf_client):
        """å±¥æ­´ã‚¯ãƒªã‚¢å¾Œã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ç¢ºèª"""
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
        with csrf_client.session_transaction() as sess:
            sess['chat_history'] = [{"human": f"msg{i}", "ai": f"resp{i}"} for i in range(100)]
            sess['scenario_history'] = {
                f"scenario{i}": [{"human": f"msg{i}", "ai": f"resp{i}"}] for i in range(50)
            }
            sess['watch_history'] = [{"speaker": "A", "message": f"msg{i}"} for i in range(100)]
        
        # å„å±¥æ­´ã‚’ã‚¯ãƒªã‚¢
        csrf_client.post('/api/clear_history', json={"mode": "chat"})
        csrf_client.post('/api/clear_history', json={"mode": "scenario"})
        csrf_client.post('/api/clear_history', json={"mode": "watch"})
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒé©åˆ‡ã«ã‚¯ãƒªã‚¢ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        with csrf_client.session_transaction() as sess:
            assert len(sess.get('chat_history', [])) == 0
            assert len(sess.get('scenario_history', {})) == 0
            assert len(sess.get('watch_history', [])) == 0


class TestRobustness:
    """å …ç‰¢æ€§ã®ãƒ†ã‚¹ãƒˆ"""
    
    # Removed patch decorator - using global mock
    def test_llm_intermittent_failures(self, csrf_client, mock_all_external_apis):
        """LLMã®æ–­ç¶šçš„ãªå¤±æ•—ã«å¯¾ã™ã‚‹å‡¦ç†ã‚’ç¢ºèª"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨
        mock_llm = mock_all_external_apis['mock_llm']
        
        # æˆåŠŸã€å¤±æ•—ã€æˆåŠŸã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨­å®š
        call_count = 0
        def side_effect(*args, **kwargs):
            nonlocal call_count
            call_count += 1
            if call_count == 2:
                raise Exception("ä¸€æ™‚çš„ãªå¤±æ•—")
            from langchain_core.messages import AIMessage
            return AIMessage(content=f"æˆåŠŸå¿œç­”{call_count}")
        
        mock_llm.invoke.side_effect = side_effect
        
        with csrf_client.session_transaction() as sess:
            sess['chat_settings'] = {
                "system_prompt": "ãƒ†ã‚¹ãƒˆ",
                "model": "gemini-1.5-flash"
            }
        
        # 3å›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆ2å›ç›®ã¯å¤±æ•—ï¼‰
        responses = []
        for i in range(3):
            response = csrf_client.post('/api/chat',
                                 json={
                                     "message": f"ãƒ†ã‚¹ãƒˆ{i+1}",
                                     "model": "gemini-1.5-flash"
                                 })
            responses.append(response)
        
        # 1å›ç›®ã¨3å›ç›®ã¯æˆåŠŸã€2å›ç›®ã¯å¤±æ•—
        assert responses[0].status_code == 200
        assert responses[1].status_code == 500
        assert responses[2].status_code == 200
    
    def test_graceful_degradation_on_service_unavailable(self, csrf_client, mock_all_external_apis):
        """ã‚µãƒ¼ãƒ“ã‚¹åˆ©ç”¨ä¸å¯æ™‚ã®é©åˆ‡ãªåŠ£åŒ–å‡¦ç†ã‚’ç¢ºèª"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨
        mock_llm = mock_all_external_apis['mock_llm']
        from langchain_core.messages import AIMessage
        mock_llm.invoke.side_effect = Exception("ã‚µãƒ¼ãƒ“ã‚¹åˆ©ç”¨ä¸å¯")
        
        with csrf_client.session_transaction() as sess:
            sess['chat_settings'] = {
                "system_prompt": "ãƒ†ã‚¹ãƒˆ",
                "model": "gemini-1.5-flash"
            }
        
        response = csrf_client.post('/api/chat',
                             json={
                                 "message": "ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ä¸­ã®ãƒ†ã‚¹ãƒˆ",
                                 "model": "gemini-1.5-flash"
                             })
        
        # ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ä¸­ã§ã‚‚é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¿”ã•ã‚Œã‚‹
        assert response.status_code == 500
        data = response.get_json()
        assert "error" in data


# ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£
@pytest.fixture
def app_context():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
    with app.app_context():
        yield app