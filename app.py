from flask import Flask, render_template, request, jsonify, session, stream_with_context
from flask_session import Session
import requests
import os
from typing import Optional, Dict, List, Tuple, Any
from datetime import datetime
from pydantic import SecretStr  # è¿½åŠ 
import asyncio
from concurrent.futures import ThreadPoolExecutor
import json
import time

# LangChainé–¢é€£
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain_core.runnables import RunnableWithMessageHistory
from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
import google.generativeai as genai
from langchain_google_genai import ChatGoogleGenerativeAI

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
from dotenv import load_dotenv
load_dotenv()

# è¨­å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import get_cached_config

# æ—¢å­˜ã®importæ–‡ã®ä¸‹ã«è¿½åŠ 
from scenarios import load_scenarios
from strength_analyzer import (
    analyze_user_strengths,
    get_top_strengths,
    generate_encouragement_messages
)
from api_key_manager import (
    get_google_api_key,
    handle_api_error,
    record_api_usage,
    get_api_key_manager
)

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from errors import (
    AppError,
    ValidationError,
    AuthenticationError,
    AuthorizationError,
    NotFoundError,
    ExternalAPIError,
    RateLimitError,
    TimeoutError,
    handle_error,
    handle_llm_specific_error,
    with_error_handling
)

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.security import SecurityUtils, CSPNonce, CSRFToken, CSRFMiddleware

# Redisé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.redis_manager import RedisSessionManager, SessionConfig, RedisConnectionError

"""
è¦ä»¶:
1. Google Gemini APIã‚’ä½¿ç”¨ã—ãŸAIãƒãƒ£ãƒƒãƒˆ
2. ãƒ¦ãƒ¼ã‚¶ã”ã¨ã«ä¼šè©±ãƒ¡ãƒ¢ãƒªã‚’ä¿æŒ
3. Geminiãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’æ©Ÿèƒ½ã®çµ±åˆ
4. Flaskã‚’ä½¿ã£ãŸãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆJinja2ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼‰
"""

app = Flask(__name__)

# Jinja2ã®è‡ªå‹•ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚’æœ‰åŠ¹åŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹ã ãŒæ˜ç¤ºçš„ã«è¨­å®šï¼‰
app.jinja_env.autoescape = True

# è¨­å®šã®èª­ã¿è¾¼ã¿
config = get_cached_config()

# Flaskè¨­å®šã®é©ç”¨
app.secret_key = config.SECRET_KEY
app.config["DEBUG"] = config.DEBUG
app.config["TESTING"] = config.TESTING
app.config["WTF_CSRF_ENABLED"] = config.WTF_CSRF_ENABLED

# ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
app.config["SESSION_TYPE"] = config.SESSION_TYPE
app.config["SESSION_LIFETIME"] = config.SESSION_LIFETIME_MINUTES * 60  # ç§’ã«å¤‰æ›

# Redisçµ±åˆã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã®åˆæœŸåŒ–
def initialize_session_store():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒˆã‚¢ã®åˆæœŸåŒ–ï¼ˆRediså„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œï¼‰"""
    try:
        # Redisè¨­å®šã‚’è©¦è¡Œ
        if config.SESSION_TYPE == "redis":
            redis_manager = RedisSessionManager(
                host=config.REDIS_HOST,
                port=config.REDIS_PORT,
                db=config.REDIS_DB,
                fallback_enabled=True
            )
            
            # Redisæ¥ç¶šç¢ºèª
            health = redis_manager.health_check()
            
            if health['connected']:
                # Redisè¨­å®šã‚’Flaskã«é©ç”¨
                redis_config = SessionConfig.get_redis_config(os.getenv('FLASK_ENV'))
                app.config.update(redis_config)
                app.config["SESSION_REDIS"] = redis_manager._client
                
                print("âœ… Redisã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒˆã‚¢ã‚’ä½¿ç”¨ã—ã¾ã™")
                print(f"   æ¥ç¶šå…ˆ: {redis_manager.host}:{redis_manager.port}")
                return redis_manager
            else:
                print(f"âš ï¸ Redisæ¥ç¶šå¤±æ•—: {health.get('error', 'Unknown error')}")
                if redis_manager.has_fallback():
                    print("   ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãŒæœ‰åŠ¹ã§ã™")
                    return redis_manager
                else:
                    raise RedisConnectionError("Redisæ¥ç¶šå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç„¡åŠ¹")
        
        # Filesystem ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        print("ğŸ“ Filesystemã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
        app.config["SESSION_TYPE"] = "filesystem"
        if config.SESSION_FILE_DIR:
            if not os.path.exists(config.SESSION_FILE_DIR):
                try:
                    os.makedirs(config.SESSION_FILE_DIR, exist_ok=True)
                except (OSError, PermissionError) as e:
                    print(f"âš ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆå¤±æ•—: {config.SESSION_FILE_DIR} - {str(e)}")
                    config.SESSION_FILE_DIR = "./flask_session"
            app.config["SESSION_FILE_DIR"] = config.SESSION_FILE_DIR
        else:
            app.config["SESSION_FILE_DIR"] = "./flask_session"
            
        return None
        
    except ImportError as e:
        print(f"âŒ Redisä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼: {str(e)}")
        print("   å¯¾å‡¦æ³•: pip install redis ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        app.config["SESSION_TYPE"] = "filesystem"
        app.config["SESSION_FILE_DIR"] = "./flask_session"
        return None
    except Exception as e:
        print(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        app.config["SESSION_TYPE"] = "filesystem"
        app.config["SESSION_FILE_DIR"] = "./flask_session"
        return None

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
redis_session_manager = initialize_session_store()

Session(app)

# CSRFå¯¾ç­–ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®åˆæœŸåŒ–
csrf = CSRFMiddleware(app)

# ========== ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®ç™»éŒ² ==========
@app.errorhandler(AppError)
def handle_app_error(error: AppError):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    return handle_error(error)

@app.errorhandler(ValidationError)
def handle_validation_error(error: ValidationError):
    """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    return handle_error(error)

@app.errorhandler(404)
def handle_not_found(error):
    """404ã‚¨ãƒ©ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    if request.path.startswith('/api/'):
        # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å ´åˆã¯JSONå½¢å¼ã§è¿”ã™
        return handle_error(NotFoundError("APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ", request.path))
    # é€šå¸¸ã®ãƒšãƒ¼ã‚¸ã®å ´åˆã¯404ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
    return render_template('404.html'), 404

@app.errorhandler(500)
def handle_internal_error(error):
    """500ã‚¨ãƒ©ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    return handle_error(Exception("å†…éƒ¨ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"))

@app.errorhandler(Exception)
def handle_unexpected_error(error: Exception):
    """äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    return handle_error(error)

# ã‚«ã‚¹ã‚¿ãƒ Jinjaãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®è¿½åŠ 
@app.template_filter('datetime')
def format_datetime(value):
    """ISOå½¢å¼ã®æ—¥æ™‚æ–‡å­—åˆ—ã‚’ã‚ˆã‚Šèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›"""
    if not value:
        return "ãªã—"
    try:
        # ISOå½¢å¼ã®æ–‡å­—åˆ—ã‚’datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        dt = datetime.fromisoformat(value)
        # æ—¥æœ¬èªå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        return dt.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
    except (ValueError, TypeError):
        return str(value)

# ========== è¨­å®šå€¤ãƒ»åˆæœŸåŒ– ==========
# Gemini APIã‚­ãƒ¼ (è¨­å®šã‹ã‚‰å–å¾—)
GOOGLE_API_KEY = config.GOOGLE_API_KEY
# ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã¯APIã‚­ãƒ¼ãŒãªãã¦ã‚‚èµ·å‹•ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
if not GOOGLE_API_KEY and not config.TESTING:
    raise ValueError("GOOGLE_API_KEY is not configured")

# LLMã®æ¸©åº¦ã‚„ãã®ä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
DEFAULT_TEMPERATURE = config.DEFAULT_TEMPERATURE

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
DEFAULT_MODEL = config.DEFAULT_MODEL

# Gemini APIã®åˆæœŸåŒ–
try:
    genai.configure(api_key=GOOGLE_API_KEY)
except Exception as e:
    print(f"Gemini API initialization error: {e}")

def get_available_gemini_models():
    """
    åˆ©ç”¨å¯èƒ½ãªGeminiãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    å»ƒæ­¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’é™¤å¤–ã—ã€ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã™ã‚‹
    """
    try:
        # Gemini APIã®è¨­å®šã‚’ç¢ºèª
        if not GOOGLE_API_KEY:
            print("Warning: GOOGLE_API_KEY is not set")
            return []
            
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        models = genai.list_models()
        
        # å»ƒæ­¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        deprecated_models = {
            'gemini-1.0-pro-vision': 'gemini-1.5-flash',
            'gemini-1.0-pro-vision-latest': 'gemini-1.5-flash-latest'
        }
        
        # Geminiãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        gemini_models = []
        for model in models:
            if "gemini" in model.name.lower():
                # ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—
                model_short_name = model.name.split('/')[-1]
                
                # å»ƒæ­¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ä»£æ›¿ã‚’ä½¿ç”¨
                if model_short_name in deprecated_models:
                    alternative = deprecated_models[model_short_name]
                    print(f"Replacing deprecated model {model_short_name} with {alternative}")
                    model_name = f"gemini/{alternative}"
                    # ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
                    if model_name not in gemini_models:
                        gemini_models.append(model_name)
                else:
                    # ãƒ¢ãƒ‡ãƒ«åã‚’æ•´å½¢ï¼ˆgemini/ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ ï¼‰
                    model_name = f"gemini/{model_short_name}"
                    gemini_models.append(model_name)
        
        print(f"Available Gemini models: {gemini_models}")
        return gemini_models
        
    except Exception as e:
        print(f"Error fetching Gemini models: {str(e)}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’è¿”ã™ï¼ˆå»ƒæ­¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’é™¤å¤–ï¼‰
        return [
            "gemini/gemini-1.5-pro",
            "gemini/gemini-1.5-flash"
        ]

def create_gemini_llm(model_name: str = "gemini-1.5-flash"):
    """
    LangChainã®Gemini Chat modelã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ
    å»ƒæ­¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•çš„ã«ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã«ç½®ãæ›ãˆã‚‹
    """
    try:
        # å»ƒæ­¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        deprecated_models = {
            'gemini-pro-vision': 'gemini-1.5-flash',
            'gemini-1.0-pro-vision': 'gemini-1.5-flash',
            'gemini-1.0-pro-vision-latest': 'gemini-1.5-flash-latest'
        }
        
        # ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰gemini/ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤
        if model_name.startswith("gemini/"):
            model_name = model_name.replace("gemini/", "")
        
        # å»ƒæ­¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        original_model = model_name
        if model_name in deprecated_models:
            model_name = deprecated_models[model_name]
            print(f"Switching from deprecated model {original_model} to {model_name}")
        
        print(f"Initializing Gemini with model: {model_name}")
        
        if not GOOGLE_API_KEY:
            raise AuthenticationError("GOOGLE_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
        # APIã‚­ãƒ¼ã®å½¢å¼ã‚’æ¤œè¨¼
        if not GOOGLE_API_KEY.startswith("AI"):
            raise ValidationError("Google APIã‚­ãƒ¼ã®å½¢å¼ãŒç„¡åŠ¹ã§ã™ã€‚'AI'ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™", field="api_key")
        
        # APIã‚­ãƒ¼ã‚’SecretStrå‹ã«å¤‰æ›
        api_key = SecretStr(GOOGLE_API_KEY)
        
        # Gemini APIã®è¨­å®šã‚’åˆæœŸåŒ–
        genai.configure(api_key=GOOGLE_API_KEY)
        
        llm = ChatGoogleGenerativeAI(
            model=model_name,
            temperature=DEFAULT_TEMPERATURE,
            api_key=api_key,
            convert_system_message_to_human=True,  # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®äº’æ›æ€§å¯¾å¿œ
        )
        
        # ãƒ†ã‚¹ãƒˆå‘¼ã³å‡ºã—ã§æ¥ç¶šç¢ºèª
        test_response = llm.invoke("test")
        if not test_response:
            raise ExternalAPIError("Gemini", "APIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“")
            
        print("Gemini model initialized successfully")
        return llm
        
    except (AuthenticationError, ValidationError, ExternalAPIError):
        # æ—¢ã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãã®ã¾ã¾å†ã‚¹ãƒ­ãƒ¼
        raise
    except Exception as e:
        # ç‰¹å®šã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒã‚§ãƒƒã‚¯
        error_msg = str(e)
        if "404" in error_msg and "deprecated" in error_msg.lower():
            # å»ƒæ­¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã§å†è©¦è¡Œ
            try:
                print(f"Error with model {model_name}: {error_msg}")
                fallback_model = "gemini-1.5-flash"
                print(f"Falling back to {fallback_model} due to deprecated model error")
                
                # å†å¸°çš„ã«ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã§è©¦è¡Œ
                return create_gemini_llm(fallback_model)
            except Exception as fallback_error:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—ã—ãŸå ´åˆã¯LLMå›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼ã«å¤‰æ›
                raise handle_llm_specific_error(fallback_error, "Gemini")
        
        # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯LLMå›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼ã«å¤‰æ›
        raise handle_llm_specific_error(e, "Gemini")

# ========== LLMç”Ÿæˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==========

# ========== ã‚·ãƒŠãƒªã‚ªï¼ˆè·å ´ã®ã‚ãªãŸå†ç¾ã‚·ãƒ¼ãƒˆã‚’æƒ³å®šã—ãŸãƒ‡ãƒ¼ã‚¿ï¼‰ ==========
# å®Ÿéš›ã«ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ãªã©ã§ç®¡ç†ã™ã‚‹ã®ãŒãŠã™ã™ã‚
scenarios = load_scenarios()

# ========== Flaskãƒ«ãƒ¼ãƒˆ ==========
@app.route("/")
def index():
    """ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸"""
    # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
    model_info = get_all_available_models()
    available_models = model_info["models"]
    
    return render_template("index.html", models=available_models)

@app.route("/chat")
def chat():
    """
    è‡ªç”±ä¼šè©±ãƒšãƒ¼ã‚¸
    """
    # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã‚’å‰Šé™¤
    return render_template("chat.html")

# æ—¢å­˜ã®handle_llm_erroré–¢æ•°ã‚’å‰Šé™¤ï¼ˆerrors.pyã®æ©Ÿèƒ½ã«ç½®ãæ›ãˆï¼‰

def create_model_and_get_response(model_name: str, messages_or_prompt, extract=True):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§LLMã‚’åˆæœŸåŒ–ã—ã€å¿œç­”ã‚’å–å¾—ã™ã‚‹å…±é€šé–¢æ•°
    
    Args:
        model_name: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        messages_or_prompt: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¾ãŸã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
        extract: å¿œç­”ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡ºã™ã‚‹ã‹ã©ã†ã‹
        
    Returns:
        ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆæŠ½å‡ºã™ã‚‹ã‹ãã®ã¾ã¾ï¼‰
    """
    try:
        llm = initialize_llm(model_name)
        response = llm.invoke(messages_or_prompt)
        
        if extract:
            return extract_content(response)
        return response
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ã¯ãã®ã¾ã¾ä¸Šä½ã«ä¼æ’­ã•ã›ã‚‹
        raise


# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°

def initialize_session_history(session_key, sub_key=None):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã‚’åˆæœŸåŒ–ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    
    Args:
        session_key: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚­ãƒ¼
        sub_key: ã‚µãƒ–ã‚­ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    if session_key not in session:
        session[session_key] = {} if sub_key else []
    
    if sub_key and sub_key not in session[session_key]:
        session[session_key][sub_key] = []
    
    session.modified = True

def add_to_session_history(session_key, entry, sub_key=None):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã«ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    
    Args:
        session_key: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚­ãƒ¼
        entry: è¿½åŠ ã™ã‚‹ã‚¨ãƒ³ãƒˆãƒªï¼ˆè¾æ›¸ï¼‰
        sub_key: ã‚µãƒ–ã‚­ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
    initialize_session_history(session_key, sub_key)
    
    # ã‚¨ãƒ³ãƒˆãƒªãŒãªã‘ã‚Œã°ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
    if "timestamp" not in entry:
        entry["timestamp"] = datetime.now().isoformat()
    
    # å±¥æ­´ã«è¿½åŠ 
    if sub_key:
        session[session_key][sub_key].append(entry)
    else:
        session[session_key].append(entry)
    
    session.modified = True

def clear_session_history(session_key, sub_key=None):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    
    Args:
        session_key: ã‚¯ãƒªã‚¢ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚­ãƒ¼
        sub_key: ã‚¯ãƒªã‚¢ã™ã‚‹ã‚µãƒ–ã‚­ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    if session_key in session:
        if sub_key:
            if sub_key in session[session_key]:
                session[session_key][sub_key] = []
        else:
            session[session_key] = {} if isinstance(session[session_key], dict) else []
    
    session.modified = True

# ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚é–“ã‚’ä¿å­˜ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’è¿½åŠ 
def set_session_start_time(session_key, sub_key=None):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    
    Args:
        session_key: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚­ãƒ¼
        sub_key: ã‚µãƒ–ã‚­ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚­ãƒ¼ã‚’æ§‹ç¯‰
    settings_key = f"{session_key}_settings"
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šãŒå­˜åœ¨ã—ãªã„å ´åˆã¯åˆæœŸåŒ–
    if settings_key not in session:
        session[settings_key] = {} if sub_key else {"start_time": datetime.now().isoformat()}
    
    # ã‚µãƒ–ã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆ
    if sub_key:
        if sub_key not in session[settings_key]:
            session[settings_key][sub_key] = {}
        session[settings_key][sub_key]["start_time"] = datetime.now().isoformat()
    else:
        session[settings_key]["start_time"] = datetime.now().isoformat()
    
    session.modified = True

# ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æ›´æ–°ã—ã¦å…±é€šé–¢æ•°ã‚’ä½¿ç”¨

def process_chat_message_legacy(message: str, model_name: str = None) -> str:
    """
    æ—¢å­˜ã®ãƒãƒ£ãƒƒãƒˆå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆA/Bãƒ†ã‚¹ãƒˆç”¨ï¼‰
    """
    if not model_name:
        model_name = DEFAULT_MODEL
    
    # chat_settingsã®å–å¾—
    chat_settings = session.get("chat_settings", {})
    system_prompt = chat_settings.get("system_prompt", "")
    
    if not system_prompt:
        raise ValidationError("ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # ä¼šè©±å±¥æ­´ã®å–å¾—ã¨æ›´æ–°
    initialize_session_history("chat_history")
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®ä½œæˆ
    messages = []
    messages.append(SystemMessage(content=system_prompt))
    
    # å±¥æ­´ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
    add_messages_from_history(messages, session["chat_history"])
    
    # æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    messages.append(HumanMessage(content=message))
    
    # å¿œç­”ã‚’ç”Ÿæˆ
    ai_message = create_model_and_get_response(model_name, messages)
    
    # ä¼šè©±å±¥æ­´ã®æ›´æ–°
    add_to_session_history("chat_history", {
        "human": message,
        "ai": ai_message
    })
    
    return ai_message

@app.route("/api/chat", methods=["POST"])
@CSRFToken.require_csrf
def handle_chat() -> Any:
    """
    ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†
    """
    data = request.get_json()
    if data is None:
        raise ValidationError("ç„¡åŠ¹ãªJSONãƒ‡ãƒ¼ã‚¿ã§ã™")

    # å…¥åŠ›å€¤ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º
    message = SecurityUtils.sanitize_input(data.get("message", ""))
    if not message:
        raise ValidationError("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç©ºã§ã™", field="message")
        
    model_name = data.get("model", DEFAULT_MODEL)
    
    # ãƒ¢ãƒ‡ãƒ«åã®æ¤œè¨¼
    if not SecurityUtils.validate_model_name(model_name):
        raise ValidationError("ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«åã§ã™", field="model")

    # chat_settingsã®å–å¾—
    chat_settings = session.get("chat_settings", {})
    system_prompt = chat_settings.get("system_prompt", "")

    if not system_prompt:
        raise ValidationError("ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")

    # ä¼šè©±å±¥æ­´ã®å–å¾—ã¨æ›´æ–°ï¼ˆå…±é€šé–¢æ•°ä½¿ç”¨ï¼‰
    initialize_session_history("chat_history")

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®ä½œæˆï¼ˆå‹ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šï¼‰
    messages: List[BaseMessage] = []
    messages.append(SystemMessage(content=system_prompt))

    # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å±¥æ­´ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
    add_messages_from_history(messages, session["chat_history"])

    # æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    messages.append(HumanMessage(content=message))

    # æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
    try:
        ai_message = process_chat_message_legacy(message, model_name)
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¦è¿”ã™
        return jsonify({"response": SecurityUtils.escape_html(ai_message)})
    except Exception as e:
        raise e

@app.route("/api/clear_history", methods=["POST"])
@CSRFToken.require_csrf
def clear_history():
    """
    ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹API
    """
    try:
        if request.json is None:
            return jsonify({"status": "error", "message": "Invalid JSON"}), 400

        mode = request.json.get("mode", "scenario")  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚·ãƒŠãƒªã‚ªãƒ¢ãƒ¼ãƒ‰
        
        if mode == "chat":
            # é›‘è«‡ãƒ¢ãƒ¼ãƒ‰ã®å±¥æ­´ã‚¯ãƒªã‚¢ï¼ˆå…±é€šé–¢æ•°ä½¿ç”¨ï¼‰
            clear_session_history("chat_history")
            if "chat_settings" in session:
                session.pop("chat_settings", None)
                session.modified = True
        elif mode == "watch":
            # è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ã®å±¥æ­´ã‚¯ãƒªã‚¢ï¼ˆå…±é€šé–¢æ•°ä½¿ç”¨ï¼‰
            clear_session_history("watch_history")
            if "watch_settings" in session:
                session.pop("watch_settings", None)
                session.modified = True
        else:
            # ã‚·ãƒŠãƒªã‚ªãƒ¢ãƒ¼ãƒ‰ã®å±¥æ­´ã‚¯ãƒªã‚¢
            selected_model = request.json.get("model", "llama2")
            scenario_id = request.json.get("scenario_id")
            
            if scenario_id:
                # ç‰¹å®šã®ã‚·ãƒŠãƒªã‚ªå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ï¼ˆå…±é€šé–¢æ•°ä½¿ç”¨ï¼‰
                clear_session_history("scenario_history", scenario_id)
            else:
                # å¤ã„å±¥æ­´å½¢å¼ã¨ã®äº’æ›æ€§ç¶­æŒ
                if "conversation_history" in session and selected_model in session["conversation_history"]:
                    session["conversation_history"][selected_model] = []
                    session.modified = True

        return jsonify({
            "status": "success", 
            "message": "ä¼šè©±å±¥æ­´ãŒã‚¯ãƒªã‚¢ã•ã‚Œã¾ã—ãŸ"
        })

    except Exception as e:
        print(f"Error in clear_history: {str(e)}")
        return jsonify({
            "status": "error",
            "message": f"å±¥æ­´ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
        }), 500

@app.route("/api/scenario_chat", methods=["POST"])
@CSRFToken.require_csrf
def scenario_chat():
    """
    ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ¢ãƒ¼ãƒ‰å°‚ç”¨ã®ãƒãƒ£ãƒƒãƒˆAPI
    """
    try:
        data = request.json
        if data is None:
            return jsonify({"error": "Invalid JSON"}), 400

        # å…¥åŠ›å€¤ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º
        user_message = SecurityUtils.sanitize_input(data.get("message", ""))
        scenario_id = data.get("scenario_id", "")
        selected_model = data.get("model", DEFAULT_MODEL)
        
        # å…¥åŠ›æ¤œè¨¼
        if not SecurityUtils.validate_scenario_id(scenario_id):
            return jsonify({"error": "ç„¡åŠ¹ãªã‚·ãƒŠãƒªã‚ªIDã§ã™"}), 400
        if not SecurityUtils.validate_model_name(selected_model):
            return jsonify({"error": "ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«åã§ã™"}), 400
        
        print(f"Received request: message={user_message}, scenario_id={scenario_id}, model={selected_model}")
        
        if not scenario_id or scenario_id not in scenarios:
            return jsonify({"error": "ç„¡åŠ¹ãªã‚·ãƒŠãƒªã‚ªIDã§ã™"}), 400

        scenario_data = scenarios[scenario_id]
        
        # ã‚»ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        system_prompt = f"""\
# ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã®åŸºæœ¬è¨­å®š
ã‚ãªãŸã¯{scenario_data["role_info"].split("ã€")[0].replace("AIã¯", "")}ã¨ã—ã¦æŒ¯ã‚‹èˆã„ã¾ã™ã€‚

## ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è©³ç´°
- æ€§æ ¼: {scenario_data["character_setting"]["personality"]}
- è©±ã—æ–¹: {scenario_data["character_setting"]["speaking_style"]}
- ç¾åœ¨ã®çŠ¶æ³: {scenario_data["character_setting"]["situation"]}

## æ¼”æŠ€ã®æŒ‡é‡
1. ä¸€è²«æ€§ï¼šè¨­å®šã•ã‚ŒãŸå½¹æŸ„ã‚’çµ‚å§‹ä¸€è²«ã—ã¦æ¼”ã˜ç¶šã‘ã‚‹ã“ã¨
2. è‡ªç„¶ã•ï¼šæŒ‡å®šã•ã‚ŒãŸè©±ã—æ–¹ã‚’å®ˆã‚ŠãªãŒã‚‰ã€ä¸è‡ªç„¶ã«ãªã‚‰ãªã„ã‚ˆã†æ³¨æ„
3. æ„Ÿæƒ…è¡¨ç¾ï¼š
   - è¡¨æƒ…ã‚„æ…‹åº¦ã‚‚å«ã‚ã¦è¡¨ç¾ï¼ˆä¾‹ï¼šã€Œå›°ã£ãŸã‚ˆã†ã«çœ‰ã‚’ã²ãã‚ãªãŒã‚‰ã€ï¼‰
   - æ„Ÿæƒ…ã®å¤‰åŒ–ã‚’é©åº¦ã«è¡¨ç¾
4. åå¿œã®é©åˆ‡ã•ï¼š
   - ç›¸æ‰‹ã®ç™ºè¨€å†…å®¹ã«å¯¾ã™ã‚‹é©åˆ‡ãªç†è§£ã¨åå¿œ
   - æ–‡è„ˆã«æ²¿ã£ãŸè¿”ç­”
5. ä¼šè©±ã®è‡ªç„¶ãªå±•é–‹ï¼š
   - ä¸€æ–¹çš„ãªä¼šè©±ã‚’é¿ã‘ã‚‹
   - é©åº¦ãªè³ªå•ã‚„ç¢ºèªã‚’å«ã‚ã‚‹
   - ç›¸æ‰‹ã®åå¿œã‚’è¦‹ãªãŒã‚‰ä¼šè©±ã‚’é€²ã‚ã‚‹

## ä¼šè©±ã®åˆ¶ç´„
1. è¿”ç­”ã®é•·ã•ï¼š1å›ã®ç™ºè¨€ã¯3è¡Œç¨‹åº¦ã¾ã§
2. è©±é¡Œã®ä¸€è²«æ€§ï¼šæ€¥ãªè©±é¡Œè»¢æ›ã‚’é¿ã‘ã‚‹
3. è·å ´ã‚‰ã—ã•ï¼šæ•¬èªã¨ç•¥èªã‚’é©åˆ‡ã«ä½¿ã„åˆ†ã‘ã‚‹

## ç¾åœ¨ã®æ–‡è„ˆ
{scenario_data["description"]}

## ç‰¹è¨˜äº‹é …
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æˆé•·ã‚’ä¿ƒã™åå¿œã‚’å¿ƒãŒã‘ã‚‹
- æ¥µç«¯ãªå¦å®šã¯é¿ã‘ã€å»ºè¨­çš„ãªå¯¾è©±ã‚’ç¶­æŒ
- å¿…è¦ã«å¿œã˜ã¦é©åº¦ãªå›°é›£ã•ã‚’æç¤º
"""
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–ï¼ˆå…±é€šé–¢æ•°ä½¿ç”¨ï¼‰
        initialize_session_history("scenario_history", scenario_id)
        
        # åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
        if len(session["scenario_history"].get(scenario_id, [])) == 0:
            set_session_start_time("scenario", scenario_id)

        try:
            # ä¼šè©±å±¥æ­´ã®æ§‹ç¯‰
            messages: List[BaseMessage] = []
            messages.append(SystemMessage(content=system_prompt))
            
            # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å±¥æ­´ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
            add_messages_from_history(messages, session["scenario_history"][scenario_id])

            # æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†
            if len(session["scenario_history"][scenario_id]) == 0:
                # åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
                prompt = f"""\
æœ€åˆã®å£°æ›ã‘ã¨ã—ã¦ã€{scenario_data["character_setting"]["initial_approach"]}ã¨ã„ã†è¨­å®šã§
è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚æ„Ÿæƒ…ã‚„è¡¨æƒ…ã‚‚è‡ªç„¶ã«å«ã‚ã¦è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚
"""
                messages.append(HumanMessage(content=prompt))
            else:
                # é€šå¸¸ã®ä¼šè©±ã®å ´åˆ
                messages.append(HumanMessage(content=user_message))

            # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
            try:
                response = create_model_and_get_response(selected_model, messages)
            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å…±é€šé–¢æ•°ã‚’ä½¿ç”¨
                error_msg, status_code, fallback_result, fallback_model = handle_llm_error(
                    e,
                    fallback_with_local_model,
                    {"messages_or_prompt": messages}
                )
                
                if fallback_result:
                    response = fallback_result
                else:
                    response = f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚{error_msg}"

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å±¥æ­´ã‚’ä¿å­˜ï¼ˆå…±é€šé–¢æ•°ä½¿ç”¨ï¼‰
            add_to_session_history("scenario_history", {
                "human": user_message if user_message else "[ã‚·ãƒŠãƒªã‚ªé–‹å§‹]",
                "ai": response
            }, scenario_id)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¦è¿”ã™
            return jsonify({"response": SecurityUtils.escape_html(response)})

        except Exception as e:
            print(f"Conversation error: {str(e)}")
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®‰å…¨ã«è¿”ã™
            error_msg = SecurityUtils.get_safe_error_message(e)
            return jsonify({"error": f"ä¼šè©±å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}"}), 500

    except Exception as e:
        print(f"General error: {str(e)}")
        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®‰å…¨ã«è¿”ã™
        error_msg = SecurityUtils.get_safe_error_message(e)
        return jsonify({"error": f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}"}), 500

@app.route("/api/scenario_clear", methods=["POST"])
def clear_scenario_history():
    """
    ç‰¹å®šã®ã‚·ãƒŠãƒªã‚ªã®å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹
    """
    try:
        data = request.json
        if not data or "scenario_id" not in data:
            return jsonify({"error": "ã‚·ãƒŠãƒªã‚ªIDãŒå¿…è¦ã§ã™"}), 400

        scenario_id = data["scenario_id"]
        if scenario_id not in scenarios:
            return jsonify({"error": "ç„¡åŠ¹ãªã‚·ãƒŠãƒªã‚ªIDã§ã™"}), 400

        # å±¥æ­´ã‚¯ãƒªã‚¢ï¼ˆå…±é€šé–¢æ•°ä½¿ç”¨ï¼‰
        clear_session_history("scenario_history", scenario_id)

        return jsonify({
            "status": "success",
            "message": "ã‚·ãƒŠãƒªã‚ªå±¥æ­´ãŒã‚¯ãƒªã‚¢ã•ã‚Œã¾ã—ãŸ"
        })

    except Exception as e:
        print(f"Error clearing scenario history: {str(e)}")
        return jsonify({
            "error": f"å±¥æ­´ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {SecurityUtils.get_safe_error_message(e)}"
        }), 500

@app.route("/api/watch/start", methods=["POST"])
@CSRFToken.require_csrf
def start_watch():
    """ä¼šè©±è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ã®é–‹å§‹"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Invalid request"}), 400

        # å…¥åŠ›å€¤ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã¨æ¤œè¨¼
        model_a = data.get("model_a")
        model_b = data.get("model_b")
        
        # ãƒ¢ãƒ‡ãƒ«åã®æ¤œè¨¼
        if not SecurityUtils.validate_model_name(model_a):
            return jsonify({"error": "ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«Aåã§ã™"}), 400
        if not SecurityUtils.validate_model_name(model_b):
            return jsonify({"error": "ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«Båã§ã™"}), 400
            
        partner_type = SecurityUtils.sanitize_input(data.get("partner_type", ""))
        situation = SecurityUtils.sanitize_input(data.get("situation", ""))
        topic = SecurityUtils.sanitize_input(data.get("topic", ""))

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–ï¼ˆå…±é€šé–¢æ•°ä½¿ç”¨ï¼‰
        clear_session_history("watch_history")
        session["watch_settings"] = {
            "model_a": model_a,
            "model_b": model_b,
            "partner_type": partner_type,
            "situation": situation,
            "topic": topic,
            "current_speaker": "A",
            "start_time": datetime.now().isoformat()  # é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
        }
        session.modified = True

        try:
            # è¦³æˆ¦ã®åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
            llm = initialize_llm(model_a)
            initial_message = generate_initial_message(
                llm, partner_type, situation, topic
            )
            
            # å±¥æ­´ã«ä¿å­˜
            session["watch_history"] = [{
                "speaker": "A", 
                "message": initial_message,
                "timestamp": datetime.now().isoformat()
            }]
            
            return jsonify({"message": f"å¤ªéƒ: {initial_message}"})

        except Exception as e:
            print(f"Error in watch initialization: {str(e)}")
            return jsonify({"error": f"è¦³æˆ¦ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}), 500

    except Exception as e:
        print(f"Error in start_watch: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/watch/next", methods=["POST"])
@CSRFToken.require_csrf
def next_watch_message() -> Any:
    """æ¬¡ã®ç™ºè¨€ã‚’ç”Ÿæˆ"""
    try:
        if "watch_settings" not in session:
            return jsonify({"error": "è¦³æˆ¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"}), 400

        settings = session["watch_settings"]
        history = session["watch_history"]

        # æ¬¡ã®è©±è€…ã‚’æ±ºå®š
        current_speaker = settings["current_speaker"]
        next_speaker = "B" if current_speaker == "A" else "A"
        model = settings["model_b"] if next_speaker == "B" else settings["model_a"]
        # è¡¨ç¤ºåã‚’è¨­å®š
        display_name = "èŠ±å­" if next_speaker == "B" else "å¤ªéƒ"

        try:
            # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
            try:
                # ã¾ãšLLMã‚’åˆæœŸåŒ–
                llm = initialize_llm(model)
                # æ¬¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
                next_message = generate_next_message(llm, history)
            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å…±é€šé–¢æ•°ã‚’ä½¿ç”¨
                error_msg, status_code, fallback_result, fallback_model = handle_llm_error(
                    e,
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã¨ã—ã¦ã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã®æ¬¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã‚’æŒ‡å®š
                    lambda fallback_model, **kwargs: generate_next_message(
                        initialize_llm(fallback_model), history
                    ),
                    {}  # è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã—
                )
                
                if fallback_result:
                    next_message = fallback_result
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ï¼ˆä»Šå¾Œã®ä¼šè©±ç”¨ï¼‰
                    if next_speaker == "B":
                        settings["model_b"] = fallback_model
                    else:
                        settings["model_a"] = fallback_model
                    
                    # æ­£å¸¸å¿œç­”ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é€šçŸ¥ä»˜ã
                    return jsonify({
                        "message": f"{display_name}(ä»£æ›¿): {next_message}", 
                        "notice": "OpenAIã®ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«ã‚ˆã‚Šã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚"
                    })
                else:
                    return jsonify({"error": error_msg}), status_code
            
            # å±¥æ­´ã«ä¿å­˜
            history.append({
                "speaker": next_speaker,
                "message": next_message,
                "timestamp": datetime.now().isoformat()
            })
            
            # è©±è€…ã‚’æ›´æ–°
            settings["current_speaker"] = next_speaker
            session.modified = True

            return jsonify({"message": f"{display_name}: {next_message}"})

        except Exception as e:
            print(f"Error generating next message: {str(e)}")
            return jsonify({"error": f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}), 500

    except Exception as e:
        print(f"Error in next_watch_message: {str(e)}")
        return jsonify({"error": str(e)}), 500

def generate_next_message(llm, history):
    """è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ã®æ¬¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    # ä¼šè©±å±¥æ­´ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    formatted_history = []
    for entry in history:
        # è©±è€…Aã¨Bã‚’å¤ªéƒã¨èŠ±å­ã«ç½®ãæ›ãˆ
        speaker_name = "å¤ªéƒ" if entry['speaker'] == "A" else "èŠ±å­"
        formatted_history.append(f"{speaker_name}: {entry['message']}")
    
    system_prompt = """ã‚ãªãŸã¯è·å ´ã§ã®è‡ªç„¶ãªä¼šè©±ã‚’è¡Œã†AIã§ã™ã€‚
ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ä¼šè©±ã‚’ç¶šã‘ã¦ãã ã•ã„ï¼š

1. å‰ã®ç™ºè¨€ã«é©åˆ‡ã«å¿œç­”ã™ã‚‹
2. è·å ´ã§ã®é©åˆ‡ãªè·é›¢æ„Ÿã‚’ä¿ã¤
3. è‡ªç„¶ãªä¼šè©±ã®æµã‚Œã‚’ç¶­æŒã™ã‚‹
4. è©±é¡Œã‚’é©åº¦ã«å±•é–‹ã™ã‚‹

å¿œç­”ã®åˆ¶ç´„ï¼š
- æ„Ÿæƒ…ã‚„ä»•è‰ã¯ï¼ˆï¼‰å†…ã«è¨˜è¿°
- ç™ºè¨€ã¯ã€Œã€ã§å›²ã‚€
- 1å›ã®å¿œç­”ã¯3è¡Œç¨‹åº¦ã¾ã§
- å¿…ãšæ—¥æœ¬èªã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹
- ãƒ­ãƒ¼ãƒå­—ã‚„è‹±èªã¯ä½¿ç”¨ã—ãªã„
"""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content="ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã«åŸºã¥ã„ã¦ã€æ¬¡ã®ç™ºè¨€ã‚’ã—ã¦ãã ã•ã„ï¼š\n\n" + "\n".join(formatted_history))
    ]
    
    response = llm.invoke(messages)
    return extract_content(response)

@app.route("/api/get_assist", methods=["POST"])
def get_assist() -> Any:
    """AIã‚¢ã‚·ã‚¹ãƒˆã®ææ¡ˆã‚’å–å¾—ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.get_json()
        scenario_id = data.get("scenario_id")
        current_context = data.get("current_context", "")

        if not scenario_id:
            return jsonify({"error": "ã‚·ãƒŠãƒªã‚ªIDãŒå¿…è¦ã§ã™"}), 400

        # ã‚·ãƒŠãƒªã‚ªæƒ…å ±ã‚’å–å¾—
        scenario = scenarios.get(scenario_id)
        if not scenario:
            return jsonify({"error": "ã‚·ãƒŠãƒªã‚ªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}), 404

        # AIã‚¢ã‚·ã‚¹ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        assist_prompt = f"""
ç¾åœ¨ã®ã‚·ãƒŠãƒªã‚ª: {scenario['title']}
çŠ¶æ³: {scenario['description']}
å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ: {', '.join(scenario['learning_points'])}

ç¾åœ¨ã®ä¼šè©±:
{current_context}

ä¸Šè¨˜ã®çŠ¶æ³ã§ã€é©åˆ‡ãªè¿”ç­”ã®ãƒ’ãƒ³ãƒˆã‚’1-2æ–‡ã§ç°¡æ½”ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚
"""

        # é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        selected_model = session.get("selected_model", DEFAULT_MODEL)
        
        try:
            # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
            suggestion = create_model_and_get_response(selected_model, assist_prompt)
            return jsonify({"suggestion": suggestion})
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å…±é€šé–¢æ•°ã‚’ä½¿ç”¨
            error_msg, status_code, fallback_result, fallback_model = handle_llm_error(
                e,
                fallback_with_local_model,
                {"messages_or_prompt": assist_prompt}
            )
            
            if fallback_result:
                return jsonify({
                    "suggestion": fallback_result, 
                    "fallback": True
                })
            else:
                return jsonify({"error": error_msg}), status_code

    except Exception as e:
        print(f"AIã‚¢ã‚·ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({"error": str(e)}), 500

# ã‚‚ã—æ¶ˆãˆã¦ã—ã¾ã£ãŸå ´åˆã«å‚™ãˆã¦extract_contenté–¢æ•°ã®å†è¿½åŠ 
def extract_content(resp: Any) -> str:
    """æ§˜ã€…ãªå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰å†…å®¹ã‚’æŠ½å‡º"""
    if isinstance(resp, AIMessage):
        return str(resp.content)
    elif isinstance(resp, str):
        return resp
    elif isinstance(resp, list):
        if not resp:  # ç©ºãƒªã‚¹ãƒˆã®å ´åˆ
            return "å¿œç­”ãŒç©ºã§ã—ãŸã€‚"
        # ãƒªã‚¹ãƒˆã®æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†
        last_msg = resp[-1]
        return extract_content(last_msg)  # å†å¸°çš„ã«å‡¦ç†
    elif isinstance(resp, dict):
        # è¾æ›¸ã®å ´åˆã€contentã‚­ãƒ¼ã‚’æ¢ã™
        if "content" in resp:
            return str(resp["content"])
        # ãã®ä»–ã®æ—¢çŸ¥ã®ã‚­ãƒ¼ã‚’ç¢ºèª
        for key in ["text", "message", "response"]:
            if key in resp:
                return str(resp[key])
    # ä¸Šè¨˜ä»¥å¤–ã®å ´åˆã¯æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦è¿”ã™
    try:
        return str(resp)
    except Exception:
        return "å¿œç­”ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

# ã‚‚ã—æ¶ˆãˆã¦ã—ã¾ã£ãŸå ´åˆã«å‚™ãˆã¦initialize_llmé–¢æ•°ã®å†è¿½åŠ 
def initialize_llm(model_name: str):
    """ãƒ¢ãƒ‡ãƒ«åã«åŸºã¥ã„ã¦é©åˆ‡ãªLLMã‚’åˆæœŸåŒ–"""
    try:
        if model_name.startswith('gemini/'):
            return create_gemini_llm(model_name.replace('gemini/', ''))
        else:
            # gemini/ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒãªã„å ´åˆã‚‚Geminiã¨ã—ã¦å‡¦ç†
            return create_gemini_llm(model_name)
    except Exception as e:
        print(f"Error in initialize_llm: {str(e)}")
        raise

# æ¬ ã‘ã¦ã„ã‚‹é–¢æ•°ã‚’è¿½åŠ 

# format_conversation_historyé–¢æ•°ã®è¿½åŠ 
def format_conversation_history(history):
    """ä¼šè©±å±¥æ­´ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã®ã¿ï¼‰"""
    formatted = []
    for entry in history:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã®ã¿ã‚’å«ã‚ã‚‹
        if entry.get("human"):
            formatted.append(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {entry['human']}")
    return "\n".join(formatted)

# get_partner_descriptioné–¢æ•°ã®è¿½åŠ 
def get_partner_description(partner_type: str) -> str:
    """ç›¸æ‰‹ã®èª¬æ˜ã‚’å–å¾—"""
    descriptions = {
        "colleague": "åŒå¹´ä»£ã®åŒåƒš",
        "senior": "å…¥ç¤¾5å¹´ç›®ç¨‹åº¦ã®å…ˆè¼©ç¤¾å“¡",
        "junior": "å…¥ç¤¾2å¹´ç›®ã®å¾Œè¼©ç¤¾å“¡",
        "boss": "40ä»£ã®èª²é•·",
        "client": "å–å¼•å…ˆã®æ‹…å½“è€…ï¼ˆ30ä»£å¾ŒåŠï¼‰"
    }
    return descriptions.get(partner_type, "åŒåƒš")

# get_situation_descriptioné–¢æ•°ã®è¿½åŠ 
def get_situation_description(situation: str) -> str:
    """çŠ¶æ³ã®èª¬æ˜ã‚’å–å¾—"""
    descriptions = {
        "lunch": "ãƒ©ãƒ³ãƒä¼‘æ†©ä¸­ã®ã‚«ãƒ•ã‚§ãƒ†ãƒªã‚¢ã§",
        "break": "åˆå¾Œã®ä¼‘æ†©æ™‚é–“ã€ä¼‘æ†©ã‚¹ãƒšãƒ¼ã‚¹ã§",
        "morning": "æœã€ã‚ªãƒ•ã‚£ã‚¹ã«åˆ°ç€ã—ã¦å¸­ã«ç€ãå‰",
        "evening": "çµ‚æ¥­å¾Œã€é€€ç¤¾æº–å‚™ã‚’ã—ã¦ã„ã‚‹æ™‚é–“",
        "party": "éƒ¨ç½²ã®æ‡‡è¦ªä¼šã§"
    }
    return descriptions.get(situation, "ã‚ªãƒ•ã‚£ã‚¹ã§")

# get_topic_descriptioné–¢æ•°ã®è¿½åŠ 
def get_topic_description(topic: str) -> str:
    """è©±é¡Œã®èª¬æ˜ã‚’å–å¾—"""
    descriptions = {
        "general": "å¤©æ°—ã‚„é€±æœ«ã®äºˆå®šãªã©ã€ä¸€èˆ¬çš„ãªè©±é¡Œ",
        "hobby": "è¶£å‘³ã‚„ä¼‘æ—¥ã®éã”ã—æ–¹ã«ã¤ã„ã¦",
        "news": "æœ€è¿‘ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„æ™‚äº‹å•é¡Œã«ã¤ã„ã¦",
        "food": "ãƒ©ãƒ³ãƒã‚„é£Ÿäº‹ã€ãŠã™ã™ã‚ã®ãŠåº—ã«ã¤ã„ã¦",
        "work": "ä»•äº‹ã«é–¢ã™ã‚‹ä¸€èˆ¬çš„ãªå†…å®¹ï¼ˆæ©Ÿå¯†æƒ…å ±ã¯é¿ã‘ã‚‹ï¼‰"
    }
    return descriptions.get(topic, "ä¸€èˆ¬çš„ãªè©±é¡Œ")

# ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’è¿½åŠ 
def get_all_available_models():
    """
    ã™ã¹ã¦ã®åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã€ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†ã™ã‚‹
    
    Returns:
        dict: ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒãƒ—ã¨ã€å…¨ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ
    """
    try:
        # Geminiãƒ¢ãƒ‡ãƒ«å–å¾—
        gemini_models = get_available_gemini_models()
        
        # æ–‡å­—åˆ—ãƒªã‚¹ãƒˆã‹ã‚‰è¾æ›¸ãƒªã‚¹ãƒˆã«å¤‰æ›
        model_dicts = []
        for model_id in gemini_models:
            model_dicts.append({
                "id": model_id,
                "name": model_id.split('/')[-1],  # gemini/xxx -> xxx
                "provider": "gemini"
            })
        
        return {
            "models": model_dicts,
            "categories": {
                "gemini": model_dicts
            }
        }
    except Exception as e:
        print(f"Error fetching models: {str(e)}")
        # åŸºæœ¬çš„ãªãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        basic_models = [
            {"id": "gemini/gemini-1.5-pro", "name": "gemini-1.5-pro", "provider": "gemini"},
            {"id": "gemini/gemini-1.5-flash", "name": "gemini-1.5-flash", "provider": "gemini"}
        ]
        return {
            "models": basic_models,
            "categories": {
                "gemini": basic_models
            }
        }

# å‰Šé™¤ã•ã‚ŒãŸãƒ«ãƒ¼ãƒˆã¨é–¢æ•°ã‚’å¾©å…ƒ

@app.route("/api/models", methods=["GET"])
def api_models():
    """
    åˆ©ç”¨å¯èƒ½ãªGeminiãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’è¿”ã™
    """
    try:
        # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
        model_info = get_all_available_models()
        return jsonify(model_info)
    except Exception as e:
        print(f"Error fetching models: {str(e)}")
        return jsonify({"error": str(e)}), 500

# ã‚·ãƒŠãƒªã‚ªä¸€è¦§ã‚’è¡¨ç¤ºã™ã‚‹ãƒšãƒ¼ã‚¸
@app.route("/scenarios")
def list_scenarios():
    """ã‚·ãƒŠãƒªã‚ªä¸€è¦§ãƒšãƒ¼ã‚¸"""
    # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
    model_info = get_all_available_models()
    available_models = model_info["models"]
    
    return render_template(
        "scenarios_list.html",
        scenarios=scenarios,
        models=available_models
    )

# ã‚·ãƒŠãƒªã‚ªã‚’é¸æŠã—ã¦ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ç”»é¢ã¸
@app.route("/scenario/<scenario_id>")
def show_scenario(scenario_id):
    """ã‚·ãƒŠãƒªã‚ªãƒšãƒ¼ã‚¸ã®è¡¨ç¤º"""
    if scenario_id not in scenarios:
        return "ã‚·ãƒŠãƒªã‚ªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", 404
    
    # ã‚·ãƒŠãƒªã‚ªå±¥æ­´ã®åˆæœŸåŒ–ï¼ˆå…±é€šé–¢æ•°ä½¿ç”¨ï¼‰
    initialize_session_history("scenario_history", scenario_id)
    
    return render_template(
        "scenario.html",
        scenario_id=scenario_id,
        scenario_title=scenarios[scenario_id]["title"],
        scenario_desc=scenarios[scenario_id]["description"],
        scenario=scenarios[scenario_id]
    )

# ãƒ¢ãƒ‡ãƒ«è©¦è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def try_multiple_models_for_prompt(prompt: str) -> Tuple[str, str, Optional[str]]:
    """
    Geminiãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹å¿œç­”ã‚’å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    
    Args:
        prompt: LLMã«ä¸ãˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        
    Returns:
        (å¿œç­”å†…å®¹, ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«å, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)ã®ã‚¿ãƒ—ãƒ«ã€‚
        ãƒ¢ãƒ‡ãƒ«ãŒå¤±æ•—ã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™ã€‚
    """
    content = None
    used_model = None
    error_msg = None
    
    try:
        # åˆ©ç”¨å¯èƒ½ãªGeminiãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª
        gemini_models = get_available_gemini_models()
        if gemini_models:
            # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸGeminiãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            model_name = gemini_models[0]
            print(f"Attempting to use Gemini model: {model_name}")
            content_result = create_model_and_get_response(model_name, prompt)
            # ç¢ºå®Ÿã«æ–‡å­—åˆ—ã«ãªã‚‹ã‚ˆã†ã«å¤‰æ›
            content = str(content_result) if content_result is not None else ""
            used_model = model_name
            print(f"Successfully generated content using {used_model}")
            return content, used_model, None
        else:
            error_msg = "No Gemini models available"
            print(error_msg)
    except Exception as gemini_error:
        print(f"Gemini model error: {str(gemini_error)}")
        error_msg = str(gemini_error)
    
    # GeminiãŒå¤±æ•—ã—ãŸå ´åˆ
    return "", "", error_msg or "Gemini model error occurred"

# ========== ä¼šè©±å±¥æ­´å‡¦ç†ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ==========
def add_messages_from_history(messages: List[BaseMessage], history, max_entries=5):
    """
    ä¼šè©±å±¥æ­´ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    
    Args:
        messages: è¿½åŠ å…ˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
        history: ä¼šè©±å±¥æ­´ï¼ˆè¾æ›¸ã®ãƒªã‚¹ãƒˆï¼‰
        max_entries: å–å¾—ã™ã‚‹æœ€å¤§ã‚¨ãƒ³ãƒˆãƒªæ•°
    """
    # ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°å‰Šæ¸›ã®ãŸã‚æœ€æ–°nä»¶ã®ã¿ï¼‰
    recent_history = history[-max_entries:] if history else []
    
    for entry in recent_history:
        if entry.get("human"):
            messages.append(HumanMessage(content=entry["human"]))
        if entry.get("ai"):
            messages.append(AIMessage(content=entry["ai"]))
    
    return messages

# ã‚·ãƒŠãƒªã‚ªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é–¢æ•°ã‚’æ›´æ–°
@app.route("/api/scenario_feedback", methods=["POST"])
@CSRFToken.require_csrf
def get_scenario_feedback():
    """ã‚·ãƒŠãƒªã‚ªã®ä¼šè©±å±¥æ­´ã«åŸºã¥ããƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ"""
    data = request.get_json()
    if data is None:
        return jsonify({"error": "Invalid JSON"}), 400

    scenario_id = data.get("scenario_id")
    if not scenario_id or scenario_id not in scenarios:
        return jsonify({"error": "ç„¡åŠ¹ãªã‚·ãƒŠãƒªã‚ªIDã§ã™"}), 400

    # ä¼šè©±å±¥æ­´ã‚’å–å¾—
    if "scenario_history" not in session or scenario_id not in session["scenario_history"]:
        return jsonify({"error": "ä¼šè©±å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}), 404

    history = session["scenario_history"][scenario_id]
    scenario_data = scenarios[scenario_id]

    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    feedback_prompt = f"""\
# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã®æŒ‡ç¤º
ã‚ãªãŸã¯è·å ´ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å°‚é–€å®¶ã¨ã—ã¦ã€ä»¥ä¸‹ã®ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã§ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¯¾å¿œã‚’è©•ä¾¡ã—ã€å…·ä½“çš„ã§å®Ÿè·µçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

## ã‚·ãƒŠãƒªã‚ªæ¦‚è¦
{scenario_data["description"]}

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç«‹å ´
{scenario_data["role_info"].split("ã€")[1]}

## ä¼šè©±å±¥æ­´ã®åˆ†æ
{format_conversation_history(history)}

## è©•ä¾¡ã®è¦³ç‚¹
{', '.join(scenario_data["feedback_points"])}

## å­¦ç¿’ç›®æ¨™
{', '.join(scenario_data["learning_points"])}

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å½¢å¼

## 1. å…¨ä½“è©•ä¾¡ï¼ˆ100ç‚¹æº€ç‚¹ï¼‰
- ç‚¹æ•°ã¨ã€ãã®ç†ç”±ã‚’ç°¡æ½”ã«èª¬æ˜

## 2. è‰¯ã‹ã£ãŸç‚¹ï¼ˆå…·ä½“ä¾‹ã‚’å«ã‚ã¦ï¼‰
- ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åŠ¹æœçš„ã ã£ãŸéƒ¨åˆ†
- ç‰¹ã«è©•ä¾¡ã§ãã‚‹å¯¾å¿œã‚„å§¿å‹¢
- ãªãœãã‚ŒãŒè‰¯ã‹ã£ãŸã®ã‹ã®èª¬æ˜

## 3. æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ
- ã‚ˆã‚ŠåŠ¹æœçš„ãªè¡¨ç¾æ–¹æ³•ã®å…·ä½“ä¾‹
- çŠ¶æ³ã«å¿œã˜ãŸå¯¾å¿œã®é¸æŠè‚¢
- å®Ÿéš›ã®è¨€ã„å›ã—ã®ä¾‹ç¤º

## 4. å®Ÿè·µã‚¢ãƒ‰ãƒã‚¤ã‚¹
1. æ˜æ—¥ã‹ã‚‰ä½¿ãˆã‚‹å…·ä½“çš„ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯
2. é¡ä¼¼ã‚·ãƒ¼ãƒ³ã§ã®å¿œç”¨ãƒã‚¤ãƒ³ãƒˆ
3. æ¬¡å›ã®ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã§ã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ

## 5. ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å‘ä¸Šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
- æˆé•·ãŒè¦‹ã‚‰ã‚ŒãŸç‚¹ã¸ã®åŠ±ã¾ã—
- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ã®æœŸå¾…
"""

    try:
        # æ–°ã—ã„ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è©¦è¡Œ
        feedback_content, used_model, error_msg = try_multiple_models_for_prompt(feedback_prompt)
        
        if feedback_content:
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä½œæˆ
            response_data = {
                "feedback": feedback_content,
                "scenario": scenario_data["title"],
                "model_used": used_model,
            }
            
            # å¼·ã¿åˆ†æã‚’è¿½åŠ 
            response_data = update_feedback_with_strength_analysis(
                response_data, "scenario", scenario_id
            )
            
            return jsonify(response_data)
        else:
            # ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒå¤±æ•—ã—ãŸå ´åˆ
            return jsonify({
                "error": f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {error_msg}",
                "attempted_models": "Gemini, OpenAI, Local"
            }), 500

    except Exception as e:
        print(f"Feedback generation error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "error": f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        }), 500

# é›‘è«‡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é–¢æ•°ã‚‚æ›´æ–°
@app.route("/api/chat_feedback", methods=["POST"])
@CSRFToken.require_csrf
def get_chat_feedback():
    """é›‘è«‡ç·´ç¿’ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ï¼‰"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Invalid request"}), 400

        # ä¼šè©±å±¥æ­´ã®å–å¾—
        if "chat_history" not in session:
            return jsonify({"error": "ä¼šè©±å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}), 404

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”¨ãƒ­ã‚°å‡ºåŠ›
        print("Chat history:", session["chat_history"])
        print("Formatted history:", format_conversation_history(session["chat_history"]))

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        feedback_prompt = f"""# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã®æŒ‡ç¤º
ã‚ãªãŸã¯é›‘è«‡ã‚¹ã‚­ãƒ«å‘ä¸Šã®ãŸã‚ã®å°‚é–€ã‚³ãƒ¼ãƒã§ã™ã€‚ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’åˆ†æã—ã€å…·ä½“çš„ã§å®Ÿè·µçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

## ä¼šè©±ã®è¨­å®š
- ç›¸æ‰‹: {get_partner_description(data.get("partner_type"))}
- çŠ¶æ³: {get_situation_description(data.get("situation"))}
- è©±é¡Œ: {get_topic_description(data.get("topic"))}

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€å±¥æ­´
{format_conversation_history(session["chat_history"])}

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å½¢å¼
## 1. å…¨ä½“è©•ä¾¡ï¼ˆ100ç‚¹æº€ç‚¹ï¼‰
- é›‘è«‡ã‚¹ã‚­ãƒ«ã®ç‚¹æ•°
- è©•ä¾¡ç†ç”±ï¼ˆç‰¹ã«è‰¯ã‹ã£ãŸç‚¹ã€æ”¹å–„ç‚¹ã‚’ç°¡æ½”ã«ï¼‰

## 2. ç™ºè¨€ã®åˆ†æ
- é©åˆ‡ãªè¨€è‘‰é£ã„ãŒã§ãã¦ã„ã‚‹éƒ¨åˆ†
- ç›¸æ‰‹ã¨ã®é–¢ä¿‚æ€§ã«é…æ…®ã§ãã¦ã„ã‚‹è¡¨ç¾
- ä¼šè©±ã®æµã‚Œã‚’ä½œã‚Œã¦ã„ã‚‹ç®‡æ‰€

## 3. æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ
- ã‚ˆã‚Šè‡ªç„¶ãªè¡¨ç¾ä¾‹
- è©±é¡Œã®åºƒã’æ–¹ã®å…·ä½“ä¾‹
- ç›¸æ‰‹ã®èˆˆå‘³ã‚’å¼•ãå‡ºã™è³ªå•ã®ä»•æ–¹

## 4. å®Ÿè·µã‚¢ãƒ‰ãƒã‚¤ã‚¹
1. å³å®Ÿè·µã§ãã‚‹ä¼šè©±ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯
2. çŠ¶æ³ã«å¿œã˜ãŸè©±é¡Œé¸ã³ã®ã‚³ãƒ„
3. é©åˆ‡ãªè·é›¢æ„Ÿã®ä¿ã¡æ–¹

## 5. ä»Šå¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã‚¢ãƒƒãƒ—
- æ¬¡å›æŒ‘æˆ¦ã—ã¦ã»ã—ã„ä¼šè©±ã‚¹ã‚­ãƒ«
- ä¼¸ã°ã›ãã†ãªå¼·ã¿ã¨ãã®æ´»ã‹ã—æ–¹
"""

        # æ–°ã—ã„ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è©¦è¡Œ
        feedback_content, used_model, error_msg = try_multiple_models_for_prompt(feedback_prompt)
        
        if feedback_content:
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä½œæˆ
            response_data = {
                "feedback": feedback_content,
                "model_used": used_model,
                "status": "success"
            }
            
            # å¼·ã¿åˆ†æã‚’è¿½åŠ 
            response_data = update_feedback_with_strength_analysis(
                response_data, "chat"
            )
            
            return jsonify(response_data)
        else:
            # ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒå¤±æ•—ã—ãŸå ´åˆ
            return jsonify({
                "error": f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {error_msg}",
                "attempted_models": "Gemini, OpenAI, Local",
                "status": "error"
            }), 500

    except Exception as e:
        print(f"Error in chat_feedback: {str(e)}")
        import traceback
        traceback.print_exc()  # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å‡ºåŠ›
        return jsonify({
            "error": f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "status": "error"
        }), 500

def generate_initial_message(llm, partner_type, situation, topic):
    """è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ã®æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    system_prompt = f"""ã‚ãªãŸã¯è·å ´ã§ã®è‡ªç„¶ãªä¼šè©±ã‚’è¡Œã†AIã§ã™ã€‚
ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ä¼šè©±ã‚’å§‹ã‚ã¦ãã ã•ã„ï¼š

è¨­å®šï¼š
- ã‚ãªãŸã¯å¤ªéƒã¨ã„ã†åå‰ã®ç¤¾å“¡ã§ã™
- ç›¸æ‰‹: èŠ±å­ã¨ã„ã†åå‰ã®{get_partner_description(partner_type)}
- çŠ¶æ³: {get_situation_description(situation)}
- è©±é¡Œ: {get_topic_description(topic)}

ä¼šè©±ã®æ³¨æ„ç‚¹ï¼š
1. è¨­å®šã•ã‚ŒãŸç›¸æ‰‹ã‚„çŠ¶æ³ã«å¿œã˜ãŸé©åˆ‡ãªè©±ã—æ–¹ã‚’ã™ã‚‹
2. è‡ªç„¶ãªä¼šè©±ã®æµã‚Œã‚’ä½œã‚‹
3. ç›¸æ‰‹ãŒè©±ã—ã‚„ã™ã„é›°å›²æ°—ã‚’ä½œã‚‹
4. è·å ´ã§ã®é©åˆ‡ãªè·é›¢æ„Ÿã‚’ä¿ã¤

å¿œç­”ã®åˆ¶ç´„ï¼š
- æ„Ÿæƒ…ã‚„ä»•è‰ã¯ï¼ˆï¼‰å†…ã«è¨˜è¿°
- ç™ºè¨€ã¯ã€Œã€ã§å›²ã‚€
- 1å›ã®å¿œç­”ã¯3è¡Œç¨‹åº¦ã¾ã§
- å¿…ãšæ—¥æœ¬èªã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹
- ãƒ­ãƒ¼ãƒå­—ã‚„è‹±èªã¯ä½¿ç”¨ã—ãªã„
- ç›¸æ‰‹ã®åå‰ã¯ã€ŒèŠ±å­ã•ã‚“ã€ã¨å‘¼ã¶

æœ€åˆã®å£°æ›ã‘ã‚’ã—ã¦ãã ã•ã„ã€‚
"""
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content="ä¼šè©±ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚")
    ]
    response = llm.invoke(messages)
    return extract_content(response)

# è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ã®ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹ãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
@app.route("/watch")
def watch_mode():
    """è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸"""
    # è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ã¯ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãŒä¸è¦ãªãŸã‚ã€ã‚·ãƒ³ãƒ—ãƒ«ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿”ã™
    return render_template("watch.html")

# å­¦ç¿’å±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹ãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
@app.route("/journal")
def view_journal():
    """å­¦ç¿’å±¥æ­´ãƒšãƒ¼ã‚¸"""
    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    scenario_history = {}
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å„ã‚·ãƒŠãƒªã‚ªã®å±¥æ­´ã‚’å–å¾—
    if "scenario_history" in session:
        for scenario_id, history in session["scenario_history"].items():
            if scenario_id in scenarios and history:
                scenario_history[scenario_id] = {
                    "title": scenarios[scenario_id]["title"],
                    "last_session": history[-1]["timestamp"] if history else None,
                    "sessions_count": len(history) // 2,  # å¾€å¾©ã®ä¼šè©±æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    "feedback": session.get("scenario_feedback", {}).get(scenario_id)
                }
    
    # é›‘è«‡å±¥æ­´ã®å–å¾—
    chat_history = []
    if "chat_history" in session:
        chat_history = session["chat_history"]
    
    # æœ€çµ‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã®æ—¥æ™‚ã‚’è¨ˆç®—
    last_activity = None
    
    # ã‚·ãƒŠãƒªã‚ªå±¥æ­´ã‹ã‚‰æœ€æ–°ã®æ—¥æ™‚ã‚’ç¢ºèª
    for scenario_data in scenario_history.values():
        if scenario_data.get("last_session"):
            if not last_activity or scenario_data["last_session"] > last_activity:
                last_activity = scenario_data["last_session"]
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‹ã‚‰ã‚‚ç¢ºèª
    if chat_history and len(chat_history) > 0:
        chat_last = chat_history[-1].get("timestamp")
        if chat_last:
            if not last_activity or chat_last > last_activity:
                last_activity = chat_last
    
    # å®Ÿéš›ã®ç·´ç¿’æ™‚é–“ã‚’è¨ˆç®—
    total_minutes = 0
    
    # ã‚·ãƒŠãƒªã‚ªã®ç·´ç¿’æ™‚é–“è¨ˆç®—
    if "scenario_settings" in session:
        scenario_settings = session["scenario_settings"]
        for scenario_id, settings in scenario_settings.items():
            if scenario_id in session.get("scenario_history", {}) and session["scenario_history"][scenario_id]:
                # é–‹å§‹æ™‚é–“ã¨æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ™‚é–“ã‹ã‚‰è¨ˆç®—
                start_time = datetime.fromisoformat(settings.get("start_time", datetime.now().isoformat()))
                last_msg_time = datetime.fromisoformat(session["scenario_history"][scenario_id][-1].get("timestamp", datetime.now().isoformat()))
                
                # å·®åˆ†ã‚’åˆ†å˜ä½ã§è¨ˆç®—
                time_diff = (last_msg_time - start_time).total_seconds() / 60
                total_minutes += time_diff
    
    # é›‘è«‡ãƒ¢ãƒ¼ãƒ‰ã®ç·´ç¿’æ™‚é–“è¨ˆç®—
    if "chat_settings" in session and "chat_history" in session and session["chat_history"]:
        chat_settings = session["chat_settings"]
        start_time = datetime.fromisoformat(chat_settings.get("start_time", datetime.now().isoformat()))
        last_msg_time = datetime.fromisoformat(session["chat_history"][-1].get("timestamp", datetime.now().isoformat()))
        
        # å·®åˆ†ã‚’åˆ†å˜ä½ã§è¨ˆç®—
        time_diff = (last_msg_time - start_time).total_seconds() / 60
        total_minutes += time_diff
    
    # è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ã®ç·´ç¿’æ™‚é–“è¨ˆç®—
    if "watch_settings" in session and "watch_history" in session and session["watch_history"]:
        watch_settings = session["watch_settings"]
        start_time = datetime.fromisoformat(watch_settings.get("start_time", datetime.now().isoformat()))
        last_msg_time = datetime.fromisoformat(session["watch_history"][-1].get("timestamp", datetime.now().isoformat()))
        
        # å·®åˆ†ã‚’åˆ†å˜ä½ã§è¨ˆç®—
        time_diff = (last_msg_time - start_time).total_seconds() / 60
        total_minutes += time_diff
    
    # æ™‚é–“ã¨åˆ†ã«å¤‰æ›ï¼ˆå°æ•°ç‚¹ä»¥ä¸‹ã‚’å››æ¨äº”å…¥ï¼‰
    total_minutes = round(total_minutes)
    hours = total_minutes // 60
    minutes = total_minutes % 60
    
    # ç·´ç¿’æ™‚é–“ã®æ–‡å­—åˆ—ã‚’æ§‹ç¯‰
    if hours > 0:
        total_practice_time = f"{hours}æ™‚é–“{minutes}åˆ†"
    else:
        total_practice_time = f"{minutes}åˆ†"
    
    # ã‚‚ã—ç·´ç¿’æ™‚é–“ãŒ0ã®å ´åˆ
    if total_minutes == 0:
        total_practice_time = "ã¾ã è¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“"
    
    return render_template(
        "journal.html",
        scenario_history=scenario_history,
        chat_history=chat_history,
        last_activity=last_activity,
        total_practice_time=total_practice_time
    )

# é›‘è«‡ç·´ç¿’é–‹å§‹ç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ 
@app.route("/api/start_chat", methods=["POST"])
def start_chat() -> Any:
    """
    é›‘è«‡ç·´ç¿’ã‚’é–‹å§‹ã™ã‚‹API
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Invalid request"}), 400
            
        model_name = data.get("model", DEFAULT_MODEL)
        partner_type = data.get("partner_type", "colleague")
        situation = data.get("situation", "break")
        topic = data.get("topic", "general")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–ã¨è¨­å®šã®ä¿å­˜
        clear_session_history("chat_history")
        session["chat_settings"] = {
            "model": model_name,
            "partner_type": partner_type,
            "situation": situation,
            "topic": topic,
            "start_time": datetime.now().isoformat(),  # é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
            "system_prompt": f"""ã‚ãªãŸã¯è·å ´ã§ã®é›‘è«‡ç·´ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
# è¨­å®š
- ç›¸æ‰‹: {get_partner_description(partner_type)}
- çŠ¶æ³: {get_situation_description(situation)}
- è©±é¡Œ: {get_topic_description(topic)}

# ä¼šè©±ã®æ–¹é‡
1. æŒ‡å®šã•ã‚ŒãŸç«‹å ´ã®äººç‰©ã¨ã—ã¦è‡ªç„¶ã«æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„
2. ç›¸æ‰‹ãŒè©±ã—ã‚„ã™ã„ã‚ˆã†ã«ã€é©åº¦ã«è³ªå•ã‚’æŠ•ã’ã‹ã‘ã¦ãã ã•ã„
3. ä¼šè©±ã®æµã‚Œã‚’ç¶­æŒã™ã‚‹ã‚ˆã†åŠªã‚ã¦ãã ã•ã„
4. ä»•äº‹ã«é–¢ã™ã‚‹è³ªå•ãŒæ¥ã¦ã‚‚ã€æ©Ÿå¯†æƒ…å ±ãªã©ã«ã¯è¨€åŠã›ãšä¸€èˆ¬çš„ãªå›ç­”ã‚’ã—ã¦ãã ã•ã„

# å¿œç­”ã®åˆ¶ç´„
- ä¸€å›ã®è¿”ç­”ã¯3è¡Œç¨‹åº¦ã«åã‚ã¦ãã ã•ã„
- é›‘è«‡ã‚‰ã—ã„è‡ªç„¶ãªå¯¾è©±ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„
- æ•¬èªã¨ç•¥èªã®ãƒãƒ©ãƒ³ã‚¹ã‚’ç›¸æ‰‹ã¨ã®é–¢ä¿‚æ€§ã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„
- æ„Ÿæƒ…è¡¨ç¾ã‚’ï¼ˆï¼‰å†…ã«é©åº¦ã«å«ã‚ã¦ãã ã•ã„"""
        }
        session.modified = True
        
        # åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”Ÿæˆ
        first_prompt = f"""
ç›¸æ‰‹: {get_partner_description(partner_type)}
çŠ¶æ³: {get_situation_description(situation)}
è©±é¡Œ: {get_topic_description(topic)}

ä¸Šè¨˜ã®è¨­å®šã§ã€ã‚ãªãŸã‹ã‚‰é›‘è«‡ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚
æœ€åˆã®å£°ã‹ã‘ã¨ã—ã¦ã€çŠ¶æ³ã«å¿œã˜ãŸè‡ªç„¶ãªæŒ¨æ‹¶ã‚„è©±é¡Œæä¾›ã‚’ã—ã¦ãã ã•ã„ã€‚
"""
        
        try:
            # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
            response = create_model_and_get_response(model_name, first_prompt)
            
            # å±¥æ­´ã«ä¿å­˜
            add_to_session_history("chat_history", {
                "human": "[é›‘è«‡é–‹å§‹]",
                "ai": response
            })
            
            return jsonify({"response": response})
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å…±é€šé–¢æ•°ã‚’ä½¿ç”¨
            error_msg, status_code, fallback_result, fallback_model = handle_llm_error(
                e,
                fallback_with_local_model,
                {"messages_or_prompt": first_prompt}
            )
            
            if fallback_result:
                # å±¥æ­´ã«ä¿å­˜
                add_to_session_history("chat_history", {
                    "human": "[é›‘è«‡é–‹å§‹]",
                    "ai": fallback_result
                })
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
                session["chat_settings"]["model"] = fallback_model
                session.modified = True
                
                return jsonify({"response": fallback_result, "notice": "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™"})
            else:
                return jsonify({"error": error_msg}), status_code
                
    except Exception as e:
        print(f"Error in start_chat: {str(e)}")
        return jsonify({"error": f"é›‘è«‡ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}), 500

@app.route("/api/conversation_history", methods=["POST"])
def get_conversation_history():
    """
    ä¼šè©±å±¥æ­´ã‚’å–å¾—ã™ã‚‹API
    """
    try:
        data = request.get_json()
        if data is None:
            return jsonify({"error": "Invalid JSON"}), 400

        history_type = data.get("type")
        
        if history_type == "scenario":
            scenario_id = data.get("scenario_id")
            if not scenario_id:
                return jsonify({"error": "ã‚·ãƒŠãƒªã‚ªIDãŒå¿…è¦ã§ã™"}), 400
                
            # æŒ‡å®šã•ã‚ŒãŸã‚·ãƒŠãƒªã‚ªã®å±¥æ­´ã‚’å–å¾—
            if "scenario_history" not in session or scenario_id not in session["scenario_history"]:
                return jsonify({"history": []})
                
            return jsonify({"history": session["scenario_history"][scenario_id]})
            
        elif history_type == "chat":
            # é›‘è«‡å±¥æ­´ã‚’å–å¾—
            if "chat_history" not in session:
                return jsonify({"history": []})
                
            return jsonify({"history": session["chat_history"]})
            
        elif history_type == "watch":
            # è¦³æˆ¦å±¥æ­´ã‚’å–å¾—
            if "watch_history" not in session:
                return jsonify({"history": []})
                
            # è¦³æˆ¦å±¥æ­´ã¯å½¢å¼ãŒç•°ãªã‚‹ã®ã§å¤‰æ›
            watch_history = []
            for entry in session["watch_history"]:
                watch_history.append({
                    "timestamp": entry.get("timestamp"),
                    "human" if entry["speaker"] == "A" else "ai": entry["message"]
                })
                
            return jsonify({"history": watch_history})
            
        else:
            return jsonify({"error": "ä¸æ˜ãªå±¥æ­´ã‚¿ã‚¤ãƒ—ã§ã™"}), 400
            
    except Exception as e:
        print(f"Error in get_conversation_history: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/tts", methods=["POST"])
def text_to_speech():
    """
    Gemini TTS APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«å¤‰æ›ã™ã‚‹API
    """
    try:
        data = request.get_json()
        if data is None:
            return jsonify({"error": "Invalid JSON"}), 400
        
        text = data.get("text", "")
        if not text:
            return jsonify({"error": "ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ã§ã™"}), 400
        
        # éŸ³å£°è¨­å®šï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸéŸ³å£°ã‚’ä½¿ç”¨ï¼‰
        voice_name = data.get("voice", "kore")  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ—¥æœ¬èªå¥³æ€§éŸ³å£°ï¼ˆå°æ–‡å­—ï¼‰
        voice_style = data.get("style", None)  # éŸ³å£°ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        emotion = data.get("emotion", None)  # æ„Ÿæƒ…ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        # æ„Ÿæƒ…ã«ã‚ˆã‚‹éŸ³å£°ã®è‡ªå‹•å¤‰æ›´ã¯è¡Œã‚ãªã„ï¼ˆã‚·ãƒŠãƒªã‚ªã”ã¨ã«å›ºå®šéŸ³å£°ã‚’ä½¿ç”¨ï¼‰
        # if emotion and not data.get("voice"):
        #     voice_name = get_voice_for_emotion(emotion)
        
        try:
            # Gemini TTS APIã‚’ä½¿ç”¨
            from google import genai
            from google.genai import types
            import base64
            import wave
            import io
            
            # APIã‚­ãƒ¼ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‹ã‚‰æ¬¡ã®ã‚­ãƒ¼ã‚’å–å¾—
            current_api_key = get_google_api_key()
            
            # Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
            client = genai.Client(api_key=current_api_key)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰ï¼ˆã‚¹ã‚¿ã‚¤ãƒ«ã®ã¿é©ç”¨ã€æ„Ÿæƒ…ã¯å£°ã®è¡¨ç¾ã§ï¼‰
            prompt = text
            if voice_style:
                prompt = f"{voice_style}: {text}"
            
            # æ„Ÿæƒ…ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹ãŒã€éŸ³å£°ã¯å¤‰æ›´ã—ãªã„
            # ã“ã‚Œã«ã‚ˆã‚ŠåŒã˜å£°å„ªãŒç•°ãªã‚‹æ„Ÿæƒ…ã‚’è¡¨ç¾ã§ãã‚‹
            if emotion and not voice_style:
                emotion_prompts = {
                    "happy": "Say cheerfully",
                    "sad": "Say sadly", 
                    "angry": "Say angrily",
                    "excited": "Say excitedly",
                    "calm": "Say calmly",
                    "tired": "Say tiredly",
                    "worried": "Say worriedly",
                    "confident": "Say confidently",
                    "friendly": "Say in a friendly manner",
                    "professional": "Say professionally",
                    "whisper": "Whisper",
                    "spooky": "Say mysteriously"
                }
                if emotion in emotion_prompts:
                    prompt = f"{emotion_prompts[emotion]}: {text}"
            
            # éŸ³å£°åˆæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä½œæˆ
            response = client.models.generate_content(
                model="models/gemini-2.5-flash-preview-tts",  # æ­£ã—ã„ãƒ¢ãƒ‡ãƒ«å
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_modalities=["AUDIO"],
                    speech_config=types.SpeechConfig(
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name=voice_name.lower(),  # å°æ–‡å­—ã«å¤‰æ›
                            )
                        )
                    ),
                )
            )
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
            print(f"TTS Response type: {type(response)}")
            print(f"Has parts: {hasattr(response, 'parts')}")
            print(f"Has candidates: {hasattr(response, 'candidates') and len(response.candidates) if hasattr(response, 'candidates') else 0}")
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå‚è€ƒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
            audio_data = None
            if hasattr(response, 'parts') and response.parts:
                part = response.parts[0]
                print(f"Using response.parts[0], type: {type(part)}")
                if hasattr(part, 'inline_data'):
                    audio_data = part.inline_data.data
                    print(f"Got inline_data.data, size: {len(audio_data) if audio_data else 0}")
            elif response.candidates and len(response.candidates) > 0:
                candidate = response.candidates[0]
                print(f"Using candidate[0], type: {type(candidate)}")
                if hasattr(candidate, 'content') and candidate.content and hasattr(candidate.content, 'parts'):
                    part = candidate.content.parts[0]
                    print(f"Got candidate.content.parts[0], type: {type(part)}")
                    if hasattr(part, 'inline_data'):
                        audio_data = part.inline_data.data
                        print(f"Got inline_data.data from candidate, size: {len(audio_data) if audio_data else 0}")
                else:
                    raise ValueError("éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            else:
                raise ValueError("ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            
            if not audio_data:
                raise ValueError("éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            
            # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆå¿…è¦ãªå ´åˆï¼‰
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯ã™ã§ã«ãƒã‚¤ãƒŠãƒªå½¢å¼ãªã®ã§ã€ãã®ã¾ã¾ä½¿ç”¨
            if isinstance(audio_data, bytes):
                audio_bytes = audio_data
                print(f"Using binary audio data, size: {len(audio_bytes)} bytes")
            elif isinstance(audio_data, str):
                # æ–‡å­—åˆ—ã®å ´åˆã¯Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
                try:
                    audio_bytes = base64.b64decode(audio_data)
                    print(f"Base64 decoded successfully, size: {len(audio_bytes)} bytes")
                except Exception as e:
                    print(f"Base64 decode error: {e}")
                    raise ValueError("éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                raise ValueError(f"äºˆæœŸã—ãªã„éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {type(audio_data)}")
            
            # WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªä¸Šã§ä½œæˆ
            wav_io = io.BytesIO()
            with wave.open(wav_io, 'wb') as wf:
                wf.setnchannels(1)  # ãƒ¢ãƒãƒ©ãƒ«
                wf.setsampwidth(2)  # 16ãƒ“ãƒƒãƒˆ
                wf.setframerate(24000)  # 24kHz
                wf.writeframes(audio_bytes)
            
            # WAVãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            wav_io.seek(0)
            wav_data = wav_io.read()
            print(f"WAV data created, size: {len(wav_data)} bytes")
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦è¿”ã™
            audio_content = base64.b64encode(wav_data).decode('utf-8')
            print(f"Base64 encoded for response, length: {len(audio_content)}")
            
            # APIä½¿ç”¨æˆåŠŸã‚’è¨˜éŒ²
            record_api_usage(current_api_key)
            
            return jsonify({
                "audio": audio_content,
                "format": "wav",
                "voice": voice_name,
                "provider": "gemini"
            })
            
        except Exception as tts_error:
            print(f"TTS error: {str(tts_error)}")
            
            # APIã‚¨ãƒ©ãƒ¼ã‚’è¨˜éŒ²
            if 'current_api_key' in locals():
                handle_api_error(current_api_key, tts_error)
            
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦Web Speech APIã®ä½¿ç”¨ã‚’ææ¡ˆ
            return jsonify({
                "error": "éŸ³å£°åˆæˆã«å¤±æ•—ã—ã¾ã—ãŸ",
                "details": str(tts_error),
                "fallback": "Web Speech API"
            }), 500
            
    except Exception as e:
        print(f"Error in text_to_speech: {str(e)}")
        return jsonify({"error": str(e)}), 500

def get_voice_for_emotion(emotion: str) -> str:
    """æ„Ÿæƒ…ã«æœ€é©ãªéŸ³å£°ã‚’é¸æŠã™ã‚‹"""
    emotion_voice_map = {
        "happy": "autonoe",  # æ˜ã‚‹ã„å¥³æ€§éŸ³å£°
        "excited": "fenrir",  # èˆˆå¥®ã—ã‚„ã™ã„ç”·æ€§éŸ³å£°
        "sad": "vindemiatrix",  # å„ªã—ã„å¥³æ€§éŸ³å£°
        "tired": "enceladus",  # æ¯ã¥ã‹ã„ã®ã‚ã‚‹ç”·æ€§éŸ³å£°
        "angry": "algenib",  # ç ‚åˆ©å£°ã®ç”·æ€§éŸ³å£°
        "worried": "achernar",  # ã‚½ãƒ•ãƒˆãªç”·æ€§éŸ³å£°
        "calm": "schedar",  # å‡ç­‰ãªä¸­æ€§éŸ³å£°
        "confident": "alnilam",  # ç¢ºå®Ÿãªç”·æ€§éŸ³å£°
        "professional": "orus",  # ä¼šç¤¾çš„ãªç”·æ€§éŸ³å£°
        "friendly": "achird",  # ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªç”·æ€§éŸ³å£°
        "whisper": "enceladus",  # æ¯ã¥ã‹ã„ã®ã‚ã‚‹éŸ³å£°
        "spooky": "umbriel"  # æ°—æ¥½ãªä¸­æ€§éŸ³å£°ï¼ˆé€†èª¬çš„ã«ä¸æ°—å‘³ã•ã‚’æ¼”å‡ºï¼‰
    }
    return emotion_voice_map.get(emotion, "kore")

# ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
image_cache = {}
MAX_CACHE_SIZE = 50  # æœ€å¤§50å€‹ã¾ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥

@app.route("/api/generate_character_image", methods=["POST"])
def generate_character_image():
    """
    AIã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç”»åƒã‚’ç”Ÿæˆã™ã‚‹API
    """
    try:
        data = request.get_json()
        if data is None:
            return jsonify({"error": "Invalid JSON"}), 400
        
        # å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¢ºèª
        scenario_id = data.get("scenario_id")
        emotion = data.get("emotion", "neutral")
        text = data.get("text", "")  # AIã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ„Ÿæƒ…æ¤œå‡ºç”¨ï¼‰
        
        if not scenario_id:
            return jsonify({"error": "ã‚·ãƒŠãƒªã‚ªIDãŒå¿…è¦ã§ã™"}), 400
        
        # ã‚·ãƒŠãƒªã‚ªæƒ…å ±ã®å–å¾—
        if scenario_id not in scenarios:
            return jsonify({"error": "ç„¡åŠ¹ãªã‚·ãƒŠãƒªã‚ªID"}), 400
        
        scenario = scenarios[scenario_id]
        character_setting = scenario.get("character_setting", {})
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã®è§£æ
        personality = character_setting.get("personality", "")
        
        # å¹´é½¢ãƒ»æ€§åˆ¥ãƒ»å½¹è·ã®æ¨å®š
        age_range = "40s"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        gender = "male"    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        position = "manager"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
        if "å¥³æ€§" in personality or "female" in personality.lower():
            gender = "female"
        elif "ç”·æ€§" in personality or "male" in personality.lower():
            gender = "male"
        
        if "20ä»£" in personality or "æ–°äºº" in personality:
            age_range = "20s"
        elif "30ä»£" in personality:
            age_range = "30s"
        elif "40ä»£" in personality:
            age_range = "40s"
        elif "50ä»£" in personality:
            age_range = "50s"
        
        if "éƒ¨é•·" in personality:
            position = "department manager"
        elif "èª²é•·" in personality:
            position = "section manager"
        elif "å…ˆè¼©" in personality:
            position = "senior colleague"
        elif "åŒåƒš" in personality:
            position = "colleague"
        elif "å¾Œè¼©" in personality or "æ–°äºº" in personality:
            position = "junior colleague"
        
        # æ„Ÿæƒ…ã‹ã‚‰è¡¨æƒ…ã¸ã®å¤‰æ›ï¼ˆè¡¨æƒ…ã®ã¿å¤‰åŒ–ã€äººç‰©ã¯åŒã˜ï¼‰
        emotion_expressions = {
            "happy": "with a warm, genuine smile and bright eyes",
            "sad": "with a concerned, sympathetic expression",
            "angry": "with a slightly frustrated but controlled expression",
            "excited": "with an enthusiastic, energetic expression",
            "worried": "with a worried, concerned look",
            "tired": "looking slightly fatigued but professional",
            "calm": "with a calm, composed expression",
            "confident": "with a confident, assured expression",
            "professional": "with a professional, neutral expression",
            "friendly": "with a friendly, approachable expression",
            "neutral": "with a neutral, attentive expression"
        }
        
        expression = emotion_expressions.get(emotion, emotion_expressions["neutral"])
        
        # ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰ï¼ˆåŒä¸€äººç‰©ã‚’ä¿è¨¼ã™ã‚‹ãŸã‚è©³ç´°ãªç‰¹å¾´ã‚’å›ºå®šï¼‰
        gender_text = "woman" if gender == "female" else "man"
        
        # ã‚·ãƒŠãƒªã‚ªã”ã¨ã®å›ºå®šçš„ãªå¤–è¦‹ç‰¹å¾´ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ä¸€è²«æ€§ã‚’ä¿ã¤ï¼‰
        # å„ã‚·ãƒŠãƒªã‚ªã«ã¯å›ºæœ‰ã®äººç‰©ã‚’å‰²ã‚Šå½“ã¦
        scenario_appearances = {
            # ç”·æ€§ä¸Šå¸ç³»
            "scenario1": "short black hair with slight gray at temples, clean-shaven, rectangular glasses, serious demeanor",
            "scenario3": "graying hair neatly styled, clean-shaven, thin-rimmed glasses, authoritative look",
            "scenario5": "dark hair with professional cut, clean-shaven, no glasses, confident bearing",
            "scenario9": "salt-and-pepper hair, clean-shaven, round glasses, thoughtful expression",
            "scenario11": "silver hair, clean-shaven, no glasses, distinguished appearance",
            "scenario13": "short black hair, clean-shaven, modern glasses, tech-savvy look",
            "scenario16": "well-groomed dark hair, clean-shaven, designer glasses, strategic thinker",
            "scenario22": "athletic build, short hair, clean-shaven, energetic presence",
            "scenario29": "experienced look, graying temples, clean-shaven, warm smile",
            
            # å¥³æ€§ä¸Šå¸ãƒ»å…ˆè¼©ç³»
            "scenario7": "shoulder-length black hair, professional style, light makeup, leadership aura",
            "scenario15": "bob-cut hair, elegant makeup, pearl earrings, managerial presence",
            "scenario17": "sophisticated short hair, refined makeup, executive appearance",
            "scenario19": "long hair in low ponytail, gentle makeup, mentoring demeanor",
            "scenario26": "stylish medium-length hair, polished makeup, PR professional look",
            
            # åŒåƒšç³»ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¤–è¦‹ï¼‰
            "default_male": "short black hair, clean-shaven, casual professional look",
            "default_female": "medium-length black hair, natural makeup, approachable appearance"
        }
        
        # ã‚·ãƒŠãƒªã‚ªã«åŸºã¥ã„ã¦å¤–è¦‹ã‚’æ±ºå®š
        if scenario_id in scenario_appearances:
            appearance = scenario_appearances[scenario_id]
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å¤–è¦‹ã‚’ä½¿ç”¨
            default_key = f"default_{gender}"
            appearance = scenario_appearances.get(default_key, "professional appearance")
        
        # ã‚ˆã‚Šå¼·åŠ›ãªåŒä¸€äººç‰©æŒ‡å®š
        # ã‚·ãƒŠãƒªã‚ªã”ã¨ã«å›ºæœ‰ã®ã‚·ãƒ¼ãƒ‰å€¤ã‚’ä½¿ç”¨
        character_seed = f"character_{scenario_id}_{gender}_{age_range}"
        
        prompt = (f"IMPORTANT: Generate the EXACT SAME person in every image. "
                 f"Character ID: {character_seed}. "
                 f"This is a professional Japanese {gender_text} in their {age_range}, "
                 f"with EXACTLY these features: {appearance}. "
                 f"They must have the SAME face structure, SAME hairstyle, SAME facial features in every image. "
                 f"Only the expression changes to show {expression}. "
                 f"Dressed in appropriate business attire for a {position}, "
                 f"in a modern Japanese office environment, "
                 f"photorealistic portrait style, high quality, "
                 f"professional lighting. "
                 f"CRITICAL: Maintain exact character consistency - same person, only expression differs.")
        
        # çŠ¶æ³ã«å¿œã˜ãŸèƒŒæ™¯ã®è¿½åŠ 
        situation = character_setting.get("situation", "")
        if "ä¼šè­°" in situation:
            prompt += ", meeting room background"
        elif "ä¼‘æ†©" in situation or "ãƒ©ãƒ³ãƒ" in situation:
            prompt += ", office break room or cafeteria background"
        elif "æ‡‡è¦ªä¼š" in situation:
            prompt += ", casual office party setting"
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã®ç”Ÿæˆï¼ˆã‚·ãƒŠãƒªã‚ªIDã¨æ„Ÿæƒ…ã®ã¿ã§æ§‹æˆï¼‰
        cache_key = f"{scenario_id}_{emotion}"
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if cache_key in image_cache:
            print(f"ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {cache_key}")
            cached_data = image_cache[cache_key]
            cached_data["cache_hit"] = True
            return jsonify(cached_data)
        
        try:
            # Gemini Image Generation APIã‚’ä½¿ç”¨
            from google import genai
            from google.genai import types
            from PIL import Image as PILImage
            from io import BytesIO
            import base64
            
            # Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
            client = genai.Client(api_key=GOOGLE_API_KEY)
            
            print(f"ç”»åƒç”Ÿæˆé–‹å§‹: {cache_key}")
            
            # ç”»åƒç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = client.models.generate_content(
                model="gemini-2.0-flash-preview-image-generation",
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_modalities=['TEXT', 'IMAGE']
                )
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            image_data = None
            generated_text = None
            
            if response.candidates and response.candidates[0].content:
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'text') and part.text:
                        generated_text = part.text
                    elif hasattr(part, 'inline_data') and part.inline_data:
                        image_data = part.inline_data.data
            
            if not image_data:
                raise ValueError("ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
            # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            if isinstance(image_data, str):
                # ã™ã§ã«Base64ã®å ´åˆ
                image_base64 = image_data
            else:
                # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è¿”å´
            response_data = {
                "image": image_base64,
                "format": "png",
                "prompt": prompt,
                "emotion": emotion,
                "character_info": {
                    "age": age_range,
                    "gender": gender,
                    "position": position
                }
            }
            
            if generated_text:
                response_data["description"] = generated_text
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼ˆã‚µã‚¤ã‚ºåˆ¶é™ã‚ã‚Šï¼‰
            if len(image_cache) >= MAX_CACHE_SIZE:
                # æœ€ã‚‚å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
                oldest_key = next(iter(image_cache))
                del image_cache[oldest_key]
                print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™ã«ã‚ˆã‚Šå‰Šé™¤: {oldest_key}")
            
            image_cache[cache_key] = response_data.copy()
            print(f"ç”»åƒã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜: {cache_key}")
            
            return jsonify(response_data)
            
        except Exception as e:
            print(f"Image generation error: {str(e)}")
            return jsonify({
                "error": "ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ",
                "details": str(e)
            }), 500
            
    except Exception as e:
        print(f"Error in generate_character_image: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/tts/voices", methods=["GET"])
def get_available_voices():
    """
    åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ã®ä¸€è¦§ã‚’å–å¾—ã™ã‚‹API
    """
    try:
        # Gemini TTSã®åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ï¼ˆå…¨30ç¨®é¡ï¼‰
        voices = [
            # ä¸»è¦ãªéŸ³å£°ï¼ˆæ—¥æœ¬èªå‘ã‘æ¨å¥¨ï¼‰
            {"id": "kore", "name": "Kore - ä¼šç¤¾çš„", "gender": "female", "provider": "gemini", "style": "professional"},
            {"id": "aoede", "name": "Aoede - è»½å¿«", "gender": "female", "provider": "gemini", "style": "breezy"},
            {"id": "callirrhoe", "name": "Callirrhoe - ãŠãŠã‚‰ã‹", "gender": "female", "provider": "gemini", "style": "easygoing"},
            {"id": "leda", "name": "Leda - è‹¥ã€…ã—ã„", "gender": "female", "provider": "gemini", "style": "youthful"},
            {"id": "algieba", "name": "Algieba - ã‚¹ãƒ ãƒ¼ã‚º", "gender": "female", "provider": "gemini", "style": "smooth"},
            {"id": "autonoe", "name": "Autonoe - æ˜ã‚‹ã„", "gender": "female", "provider": "gemini", "style": "bright"},
            {"id": "despina", "name": "Despina - ã‚¹ãƒ ãƒ¼ã‚º", "gender": "female", "provider": "gemini", "style": "smooth"},
            {"id": "erinome", "name": "Erinome - ã‚¯ãƒªã‚¢", "gender": "female", "provider": "gemini", "style": "clear"},
            {"id": "laomedeia", "name": "Laomedeia - ã‚¢ãƒƒãƒ—ãƒ“ãƒ¼ãƒˆ", "gender": "female", "provider": "gemini", "style": "upbeat"},
            {"id": "pulcherrima", "name": "Pulcherrima - å‰å‘ã", "gender": "female", "provider": "gemini", "style": "forward"},
            {"id": "vindemiatrix", "name": "Vindemiatrix - å„ªã—ã„", "gender": "female", "provider": "gemini", "style": "gentle"},
            
            # ç”·æ€§éŸ³å£°
            {"id": "enceladus", "name": "Enceladus - æ¯ã¥ã‹ã„", "gender": "male", "provider": "gemini", "style": "breathy"},
            {"id": "charon", "name": "Charon - æƒ…å ±æä¾›çš„", "gender": "male", "provider": "gemini", "style": "informative"},
            {"id": "fenrir", "name": "Fenrir - èˆˆå¥®ã—ã‚„ã™ã„", "gender": "male", "provider": "gemini", "style": "excitable"},
            {"id": "orus", "name": "Orus - ä¼šç¤¾çš„", "gender": "male", "provider": "gemini", "style": "corporate"},
            {"id": "iapetus", "name": "Iapetus - ã‚¯ãƒªã‚¢", "gender": "male", "provider": "gemini", "style": "clear"},
            {"id": "algenib", "name": "Algenib - ç ‚åˆ©å£°", "gender": "male", "provider": "gemini", "style": "gravelly"},
            {"id": "rasalgethi", "name": "Rasalgethi - æƒ…å ±è±Šå¯Œ", "gender": "male", "provider": "gemini", "style": "informative"},
            {"id": "achernar", "name": "Achernar - ã‚½ãƒ•ãƒˆ", "gender": "male", "provider": "gemini", "style": "soft"},
            {"id": "alnilam", "name": "Alnilam - ç¢ºå®Ÿ", "gender": "male", "provider": "gemini", "style": "assured"},
            {"id": "gacrux", "name": "Gacrux - æˆç†Ÿ", "gender": "male", "provider": "gemini", "style": "mature"},
            {"id": "achird", "name": "Achird - ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼", "gender": "male", "provider": "gemini", "style": "friendly"},
            {"id": "zubenelgenubi", "name": "Zubenelgenubi - ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«", "gender": "male", "provider": "gemini", "style": "casual"},
            {"id": "sadachbia", "name": "Sadachbia - æ´»ç™º", "gender": "male", "provider": "gemini", "style": "lively"},
            {"id": "sadaltager", "name": "Sadaltager - çŸ¥è­˜è±Šå¯Œ", "gender": "male", "provider": "gemini", "style": "knowledgeable"},
            {"id": "sulafat", "name": "Sulafat - æ¸©ã‹ã„", "gender": "male", "provider": "gemini", "style": "warm"},
            
            # ä¸­æ€§éŸ³å£°
            {"id": "puck", "name": "Puck - ã‚¢ãƒƒãƒ—ãƒ“ãƒ¼ãƒˆ", "gender": "neutral", "provider": "gemini", "style": "upbeat"},
            {"id": "zephyr", "name": "Zephyr - æ˜ã‚‹ã„", "gender": "neutral", "provider": "gemini", "style": "bright"},
            {"id": "umbriel", "name": "Umbriel - æ°—æ¥½", "gender": "neutral", "provider": "gemini", "style": "easygoing"},
            {"id": "schedar", "name": "Schedar - å‡ç­‰", "gender": "neutral", "provider": "gemini", "style": "even"}
        ]
        
        # Web Speech APIï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        voices.append({
            "id": "web-speech", 
            "name": "ãƒ–ãƒ©ã‚¦ã‚¶éŸ³å£°åˆæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰", 
            "gender": "various", 
            "provider": "browser"
        })
        
        return jsonify({"voices": voices})
        
    except Exception as e:
        print(f"Error in get_available_voices: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/tts/styles", methods=["GET"])
def get_available_styles():
    """
    åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ã‚¹ã‚¿ã‚¤ãƒ«ã¨æ„Ÿæƒ…ã®ä¸€è¦§ã‚’å–å¾—ã™ã‚‹API
    """
    try:
        styles = {
            "emotions": [
                {"id": "happy", "name": "æ¥½ã—ã„ãƒ»å¬‰ã—ã„", "description": "æ˜ã‚‹ãå…ƒæ°—ãªæ„Ÿã˜"},
                {"id": "sad", "name": "æ‚²ã—ã„ãƒ»å¯‚ã—ã„", "description": "å„ªã—ãç©ã‚„ã‹ãªæ„Ÿã˜"},
                {"id": "angry", "name": "æ€’ã‚Šãƒ»ä¸æº€", "description": "åŠ›å¼·ãæ–­å®šçš„ãªæ„Ÿã˜"},
                {"id": "excited", "name": "èˆˆå¥®ãƒ»ãƒ¯ã‚¯ãƒ¯ã‚¯", "description": "æ´»ç™ºã§ã‚¨ãƒãƒ«ã‚®ãƒƒã‚·ãƒ¥"},
                {"id": "worried", "name": "å¿ƒé…ãƒ»ä¸å®‰", "description": "æ§ãˆã‚ã§æ…é‡ãªæ„Ÿã˜"},
                {"id": "tired", "name": "ç–²ã‚Œãƒ»çœ ã„", "description": "ã‚†ã£ãã‚Šã¨æ¯é£ã„ã®ã‚ã‚‹æ„Ÿã˜"},
                {"id": "calm", "name": "è½ã¡ç€ããƒ»å®‰å¿ƒ", "description": "ç©ã‚„ã‹ã§å®‰å®šã—ãŸæ„Ÿã˜"},
                {"id": "confident", "name": "è‡ªä¿¡ãƒ»ç¢ºä¿¡", "description": "ã¯ã£ãã‚Šã¨æ˜ç¢ºãªæ„Ÿã˜"},
                {"id": "professional", "name": "ãƒ“ã‚¸ãƒã‚¹ãƒ»ä¸å¯§", "description": "ãƒ•ã‚©ãƒ¼ãƒãƒ«ã§ç¤¼å„€æ­£ã—ã„"},
                {"id": "friendly", "name": "è¦ªã—ã¿ãƒ»æ°—ã•ã", "description": "æ¸©ã‹ãè¦ªã—ã¿ã‚„ã™ã„"},
                {"id": "whisper", "name": "ã•ã•ã‚„ã", "description": "é™ã‹ã§å¯†ã‚„ã‹ãªæ„Ÿã˜"},
                {"id": "spooky", "name": "ä¸æ°—å‘³ãƒ»æ€–ã„", "description": "ç¥ç§˜çš„ã§è–„æ°—å‘³æ‚ªã„"}
            ],
            "custom_styles": [
                {"example": "in a storytelling manner", "description": "ç‰©èªã‚’èªã‚‹ã‚ˆã†ãªå£èª¿ã§"},
                {"example": "like a news anchor", "description": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã®ã‚ˆã†ã«"},
                {"example": "as if giving a presentation", "description": "ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã™ã‚‹ã‚ˆã†ã«"},
                {"example": "in a comforting way", "description": "æ…°ã‚ã‚‹ã‚ˆã†ãªå„ªã—ã„å£èª¿ã§"},
                {"example": "with dramatic emphasis", "description": "ãƒ‰ãƒ©ãƒãƒãƒƒã‚¯ã«å¼·èª¿ã—ã¦"}
            ]
        }
        
        return jsonify(styles)
        
    except Exception as e:
        print(f"Error in get_available_styles: {str(e)}")
        return jsonify({"error": str(e)}), 500


# ========== å¼·ã¿åˆ†ææ©Ÿèƒ½ ==========
@app.route("/strength_analysis")
def strength_analysis_page():
    """å¼·ã¿åˆ†æãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    return render_template("strength_analysis.html")


@app.route("/api/strength_analysis", methods=["POST"])
def analyze_strengths():
    """ä¼šè©±å±¥æ­´ã‹ã‚‰å¼·ã¿ã‚’åˆ†æ"""
    try:
        data = request.get_json()
        if data is None:
            return jsonify({"error": "Invalid JSON"}), 400
            
        session_type = data.get("type", "chat")  # chat or scenario
        scenario_id = data.get("scenario_id")
        
        # ä¼šè©±å±¥æ­´ã‚’å–å¾—
        if session_type == "chat":
            history = session.get("chat_history", [])
        elif session_type == "scenario":
            if not scenario_id:
                return jsonify({"error": "ã‚·ãƒŠãƒªã‚ªIDãŒå¿…è¦ã§ã™"}), 400
            elif scenario_id == "all":
                # å…¨ã‚·ãƒŠãƒªã‚ªã®å±¥æ­´ã‚’çµåˆ
                scenario_histories = session.get("scenario_history", {})
                history = []
                for scenario_id, scenario_history in scenario_histories.items():
                    history.extend(scenario_history)
            else:
                history = session.get("scenario_history", {}).get(scenario_id, [])
        else:
            return jsonify({"error": f"ä¸æ˜ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—: {session_type}"}), 400
        
        if not history:
            return jsonify({
                "scores": {key: 50 for key in ["empathy", "clarity", "active_listening", 
                          "adaptability", "positivity", "professionalism"]},
                "messages": ["ã¾ã ç·´ç¿’å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¼šè©±ã‚’å§‹ã‚ã¦ã¿ã¾ã—ã‚‡ã†ï¼"],
                "history": []
            })
        
        # ä¼šè©±å±¥æ­´ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted_history = format_conversation_history(history)
        
        # å¼·ã¿åˆ†æã‚’å®Ÿè¡Œï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
        scores = analyze_user_strengths(formatted_history)
        
        # ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«åï¼ˆä»Šã¯ã‚·ãƒ³ãƒ—ãƒ«åˆ†æãªã®ã§å›ºå®šï¼‰
        used_model = "simple_analyzer"
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ã•ã‚Œã‚‹å¼·ã¿å±¥æ­´ã‚’æ›´æ–°
        if "strength_history" not in session:
            session["strength_history"] = {}
        
        if session_type not in session["strength_history"]:
            session["strength_history"][session_type] = []
        
        # æ–°ã—ã„åˆ†æçµæœã‚’è¿½åŠ 
        session["strength_history"][session_type].append({
            "timestamp": datetime.now().isoformat(),
            "scores": scores,
            "practice_count": len(session["strength_history"][session_type]) + 1
        })
        
        # æœ€å¤§20ä»¶ã¾ã§ä¿æŒ
        if len(session["strength_history"][session_type]) > 20:
            session["strength_history"][session_type] = session["strength_history"][session_type][-20:]
        
        session.modified = True
        
        # åŠ±ã¾ã—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
        messages = generate_encouragement_messages(
            scores,
            session["strength_history"][session_type][:-1]  # ç¾åœ¨ã®çµæœã‚’é™¤ã
        )
        
        # ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ï¼ˆ1ã¤ç›®ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚‹å ´åˆï¼‰
        if messages and len(messages) < 3:
            top_strength = get_top_strengths(scores, 1)[0]
            additional_messages = [
                f"{top_strength['name']}ã®æ‰èƒ½ãŒå…‰ã£ã¦ã„ã¾ã™ï¼ã“ã®å¼·ã¿ã‚’æ´»ã‹ã—ã¦ã•ã‚‰ã«æˆé•·ã—ã¾ã—ã‚‡ã†ã€‚",
                f"ç´ æ™´ã‚‰ã—ã„{top_strength['name']}ã§ã™ã­ï¼æ¬¡å›ã¯ã•ã‚‰ã«ç£¨ãã‚’ã‹ã‘ã¦ã„ãã¾ã—ã‚‡ã†ã€‚",
                f"{top_strength['name']}ãŒ{top_strength['score']}ç‚¹ï¼ã‚ãªãŸã®å¼·ã¿ã‚’è‡ªä¿¡ã«ã—ã¦å‰é€²ã—ã¾ã—ã‚‡ã†ã€‚"
            ]
            import random
            messages.append(random.choice(additional_messages))
        
        return jsonify({
            "scores": scores,
            "messages": messages,
            "history": session["strength_history"][session_type],
            "model_used": used_model
        })
        
    except Exception as e:
        print(f"Error in analyze_strengths: {str(e)}")
        return jsonify({"error": str(e)}), 500


def update_feedback_with_strength_analysis(feedback_response, session_type, scenario_id=None):
    """
    æ—¢å­˜ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å¼·ã¿åˆ†æã‚’è¿½åŠ ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    """
    try:
        # ä¼šè©±å±¥æ­´ã‚’å–å¾—
        if session_type == "chat":
            history = session.get("chat_history", [])
        else:
            history = session.get("scenario_history", {}).get(scenario_id, [])
        
        if history:
            # å¼·ã¿åˆ†æã‚’å®Ÿè¡Œï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
            formatted_history = format_conversation_history(history)
            scores = analyze_user_strengths(formatted_history)
            
            # ãƒˆãƒƒãƒ—3ã®å¼·ã¿ã‚’å–å¾—
            top_strengths = get_top_strengths(scores, 3)
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«è¿½åŠ 
            feedback_response["strength_analysis"] = {
                "scores": scores,
                "top_strengths": top_strengths
            }
    except Exception as e:
        print(f"Error adding strength analysis to feedback: {str(e)}")
    
    return feedback_response


# ========== APIã‚­ãƒ¼ç®¡ç† ==========
@app.route("/api/key_status", methods=["GET"])
def get_api_key_status():
    """APIã‚­ãƒ¼ã®ä½¿ç”¨çŠ¶æ³ã‚’å–å¾—"""
    try:
        manager = get_api_key_manager()
        status = manager.get_status()
        return jsonify(status)
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ========== ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ»ç›£è¦– ==========
@app.route("/api/session/health", methods=["GET"])
def session_health_check():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒˆã‚¢ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
    try:
        if redis_session_manager:
            health = redis_session_manager.health_check()
            connection_info = redis_session_manager.get_connection_info()
            
            return jsonify({
                "status": "healthy" if health['connected'] else "degraded",
                "session_store": "redis" if health['connected'] else "fallback",
                "details": {
                    "redis_connected": health['connected'],
                    "fallback_active": health['fallback_active'],
                    "connection_info": connection_info,
                    "error": health.get('error')
                }
            })
        else:
            return jsonify({
                "status": "healthy",
                "session_store": "filesystem",
                "details": {
                    "redis_connected": False,
                    "fallback_active": False,
                    "session_dir": app.config.get("SESSION_FILE_DIR", "./flask_session")
                }
            })
            
    except Exception as e:
        return jsonify({
            "status": "error",
            "error": f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }), 500


@app.route("/api/session/info", methods=["GET"])
def session_info():
    """ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—"""
    try:
        session_data = {
            "session_id": session.get('_id', 'N/A'),
            "session_keys": list(session.keys()),
            "session_type": app.config.get("SESSION_TYPE", "unknown"),
            "permanent": session.permanent,
            "has_chat_history": 'chat_history' in session,
            "has_scenario_history": 'scenario_chat_history' in session,
            "current_scenario": session.get('current_scenario_id'),
            "model_choice": session.get('model_choice', 'N/A')
        }
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºã®æ¦‚ç®—
        import sys
        session_size = sys.getsizeof(str(dict(session)))
        session_data["estimated_size_bytes"] = session_size
        
        return jsonify(session_data)
        
    except Exception as e:
        return jsonify({"error": f"ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"}), 500


@app.route("/api/session/clear", methods=["POST"])
@CSRFToken.require_csrf
def clear_session_data():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªã‚¢"""
    try:
        data = request.json or {}
        clear_type = data.get("type", "all")
        
        if clear_type == "all":
            session.clear()
            message = "å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ"
        elif clear_type == "chat":
            session.pop('chat_history', None)
            message = "ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ"
        elif clear_type == "scenario":
            session.pop('scenario_chat_history', None)
            session.pop('current_scenario_id', None)
            message = "ã‚·ãƒŠãƒªã‚ªå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ"
        elif clear_type == "watch":
            session.pop('watch_history', None)
            message = "è¦³æˆ¦å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ"
        else:
            return jsonify({"error": "ç„¡åŠ¹ãªã‚¯ãƒªã‚¢ã‚¿ã‚¤ãƒ—ã§ã™"}), 400
        
        return jsonify({
            "status": "success",
            "message": message,
            "cleared_type": clear_type
        })
        
    except Exception as e:
        return jsonify({
            "error": f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }), 500


# ========== ãƒ¡ã‚¤ãƒ³èµ·å‹• ==========
# ============= A/Bãƒ†ã‚¹ãƒˆç”¨Blueprintç™»éŒ² =============
try:
    from routes.ab_test_routes import ab_test_bp
    app.register_blueprint(ab_test_bp)
    print("âœ… A/Bãƒ†ã‚¹ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ç™»éŒ²ã—ã¾ã—ãŸ (/api/v2/*)")
except ImportError as e:
    print(f"âš ï¸ A/Bãƒ†ã‚¹ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯åˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")

if __name__ == "__main__":
    # è¨­å®šã«åŸºã¥ã„ã¦ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
    app.run(
        debug=config.DEBUG,
        host=config.HOST,
        port=config.PORT,
        use_reloader=config.HOT_RELOAD
    )
